---
layout: post
title:  "아파치 카프카 스터디 - 4"
date:   2023-01-17 23:20:21 +0900
categories: kafka, spring
---

> 아프치 카프카 애플리케이션 프로그래밍 스터디 - 4


# 목표?
- 회사에서 대용량 데이터를 처리하는것에 있어, 카프카를 사용하고 있으므로, 제대로된 학습을 통해 원하는 처리를 할 수 있도록 한다.


# 카프카 스트림즈
> 토픽에 적재된 데이터를 상태기반 또는 비상태기반으로 실시간 변환하여 다른 토픽에 적재하는 라이브러리

## 스트림즈 애플리케이션
- 내부적으로 스레드를 1개 이상 생성할 수 있으며, 스레드는 1개 이상 테스크를 가진다.
- 스트림즈의 테스크는 스트림즈 어플리케이션을 실행하면 생기는 데이터 처리 최소단위이다.
- 3개의 파티션으로 이루어진 토픽을 처리하는 스트림즈 애플리케이션을 실행하면 내부에 3개의 테스크가 생긴다.
- 컨슈머의 병렬처리를 위해 컨슈머 그룹으로 이루어진 컨슈머 스레드를 여러 개 실행하는 것과 비슷하다.

## 토폴로지
> 2개 이상의 노드들과 선으로 이루어진 집합
- 링형, 트리형, 성형등이 있다.
- 카프카스트림즈에서는 토폴로지를 이루는 노드를 하나의 프로세서라고 부르고, 노드와 노드를 이은 선을 스트림이라고 한다.
- 스트림은 `토픽의 데이터` 뜻하고, 프로듀서와 컨슈머에서 활용했던 레코드와 동일하다.
- Processor 3가지
    - 소스 프로세서
        - 데이터를 처리하기 위해 최초로 선언해야하는 노드로 하나 이상의 데이터를 가져오는 역할
    - 스트림 프로세서
        - 다른 프로세서가 반환된 데이터를 처리하는 역할, 변환 분기 처리와 같은 데이터처리
    - 싱크 프로세서
        - 데이터를 특정 카프카 토픽으로저장하는 역할하며, 최종 종착지 역할


## 스트림즈 DSL
- 프로세서 API 2가지 방법으로 개발 가능하다.
- 스트림즈 DSL로 구현하는 데이터 처리 예시
    - 지난 10분간 들어온 데이터 집계
    - 메시지 값을 기반으로 토픽 분기처리
    - 토픽과 다른 토픽의 결합으로 새로운 데이터 생성
- 프로세서 API 구현하는 데이터 처리 예시
    - 메시지 값의 종류에 따라 토픽을 가변적으로 전송
    - 일정한 시간 간격으로 데이터 처리
- `KStream`
- `KTable`
- `GlobalKTable`

## KStream
- 레코드의 흐름을 표현한 것으로 메시지 키와 메시지 값으로 구성되어 있다.
- KStream으로 데이터를 조회하면 토픽에 존재하는 모든 레코드가 출력된다.
- KStream은 컨슈머로 토픽을 구독하는 것과 동일한 선상에서 사용하는 것이라고 볼 수 있다.

## KTable
- KStream과 다르게 메시지 키를 기준으로 묶어 사용한다.
- KStream은 토픽의 모든 레코드를 조회할 수 있지만, KTable은 유니크한 메시지키를 기준으로 가장 최신 레코드를 사용한다.

## GlobalKTable
- KTable과 동일하게 메시지 키를 기준으로 묶어 사용된다.
- 그러나 KTable로 선언된 토픽은 1개 파티션이 1개 테스크에 할당되어 사용되고, GlobalKTable로 선언된 토픽은 모든 파티션 데이터가 각 테스크에 할당되어 사용된다는 차이점이 있다.
- KStream과 KTable 데이터를 조인한다고 가정했을때
    - KStream과 KTable을 조인하려면 반드시 `코파티셔닝` 되어 있어야한다.
        - 코파티셔닝이란? 조인을 하는 2개 데이터의 파티션 개수가 동일하고 파티셔닝 전략을 동일하게 맞추는 작업
        - 파티션 개수가 동일하고 파티셔닝 전략이 같은 경우에는 동일한 메시지 키를 가진 데이터가 동일한 테스크에 들어가는것을 보장한다. => 조인가능
    - 문제는 KStream과 KTable이 동일하게 파티션을 가지고 있다고 보장할 수 없다.
    - 코파티셔닝이 되어있지 않으면 리파티셔닝하는 과정을 거쳐 새로운 토픽에 새로운 메시지 키를 가지도록 재배열한다.
    - 리파티셔닝 과정은 토픽에 데이터를 중복해서 생성할 뿐만 아니라 파티션을 재배열하기 위해 프로세싱하는 과정도 거쳐야한다.
- GlobalKTable은 조인해서 사용하고 싶다면 KTable을 GlobalKTable로 선언하여 사용하면된다.
    - GlobalKTable은 코파티셔닝되지 않은 KStream과 조인할 수 있다. 왜냐하면 `KTable과 다르게 GlobalKTabl로 정의된 데이터는 스트림즈 어플리케이션의 모든 테스크에 동일하게 공유되어 사용한다.`
    - 다만 많은 양의 데이터를 사용하게 되면 로컬 스토리지의 사용량이 증가하여, 네트워크, 브로커에 많은 부하가 생겨 데이터가 작은 것만 사용하자.
    - 많은 양의 데이터는 리파티셔닝을 통해 KTable을 사용하는것이 좋다.

## 스트림즈 DSL 옵션
- 주요
    - bootstrap.servers: 프로듀서가 데이터를 전송할 대상 카프카 클러스터에 속한 브로커의 호스트이름:포트를 1개 이상 작성한다. 2개 이상 브로커 정보를 입력하여 일부 브로커에 이슈가 발생하더라도 접속하는 데에 이슈가 없도록 설저 가능하다.
    - application.id: 스트림즈 애플리케이션을 구분하기 위한 고유 아이디를 설정, 다른 로직을 가진 스트림즈 애플리케이션들은 서로 다른 application.id를 가져야한다.
- 선택
    - default.`key,value`.serde: 레코드의 메시지 키, 벨류를 직렬화, 역질렬화 하는 클래스를 지정, default는 바이트 직렬/역질렬화 클래스인 `Serdes.ByteArray().getClass().getName()`
    - num.stream.threads: 스트림 프로세싱 실행 시 실행될 스레드 개수를 지정한다. 기본 값은 1
    - state.dir: rockDB 저장소가 위치할 디렉토리를 지정한다. rocksDB는 페이스북이 개발한 고성능 key-value DB로서 카프카 스트림즈가 상태기반 데이터를 처리할 때 로컬 저장소로 사용. 기본 값은 /tmp/kafka-streams


## 실습
- stream(), to()
    - 특정 토픽의 데이터를 다른 토픽으로 전달하는 것  (stream_log 토픽에서 stream_log_copy 토픽으로 동일한 데이터를 옮기는 요구사항을 구현해보자.)

~~~
bin/kafka-topics.sh --create \
> --bootstrap-server my-kafka:9092 \
> --partitions 3 \
> --topic stream_log


~~~


```java
public class SimpleStreamApplication {
    private static String APPLICATION_NAME = "streams-application";
    private static String BOOTSTRAP_SERVER = "my-kafka:9092";
    private static String STREAM_LOG = "stream_log";
    private static String STREAM_LOG_COPY = "stream_log_copy";

    public static void main(String[] args) {
        Properties props = new Properties();
        props.put(StreamsConfig.APPLICATION_ID_CONFIG, APPLICATION_NAME);
        props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVER);
        props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());
        props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());

        // 스트림 토폴로지를 정의하기 위한 용도
        StreamsBuilder builder = new StreamsBuilder();
        // stream_log로부터 KStream 객체를 만들기위해 StreamsBuilder.stream() 메서드 사용
        // stream() 외에 KTable을 만드는 table(), globalKTable() 메서드도 지원 < 이 메소드들은 최초의 토픽 데이터를 가져오는 소스 프로세서이다.
        KStream<String, String> stream = builder.stream(STREAM_LOG);

        // stream_log 토픽을 담은 KStream 객체를 다른 토픽으로 전송하기위해 to() 실행
        // to() 메서드는 KStream 인스턴스의 데이터들을 특정 토픽으로 저장하기 위한 용도로 사용 < 싱크 프로세서
        stream.to(STREAM_LOG_COPY);

        KafkaStreams streams = new KafkaStreams(builder.build(), props);
        streams.start();
    }
}

```

- filter
```java
public class StreamFilter {
    private static String APPLICATION_NAME = "streams-application";
    private static String BOOTSTRAP_SERVER = "my-kafka:9092";
    private static String STREAM_LOG = "stream_log";
    private static String STREAM_LOG_FILTER = "stream_log_filter";

    public static void main(String[] args) {
        Properties props = new Properties();
        props.put(StreamsConfig.APPLICATION_ID_CONFIG, APPLICATION_NAME);
        props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVER);
        props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());
        props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());

        StreamsBuilder builder = new StreamsBuilder();
        KStream<String, String> stream = builder.stream(STREAM_LOG);

        KStream<String, String> filteredStream = stream.filter((k, v) -> v.length() > 5); // 새로운 객체로 생성해야하네?

        filteredStream.to(STREAM_LOG_FILTER);

        KafkaStreams streams = new KafkaStreams(builder.build(), props);
        streams.start();
    }
}
```

## KTable과 KStream join()
- 메시지 키를 기준으로 조인
- 실시간으로 들어오는 데이터를 조인할 수 있다.
    - 예) 이름을 메시지 키, 주소를 메시지 값으로 가지고 있는 KTable이 있고 이름을 메시지 키, 주문한 물품을 메시지 값으로 가지고 있는 KStream이 있다면 사용자가 물품을 주문하면 이미 토픽에 저장된 이름:주소 KTable과 이름:주문물품을 가진 KStream을 조인하여 새로운 데이터를 생성할 수 있다.
- 주의할점은 코파티셔닝이 되어있는지 확인해야한다.

~~~
--bootstrap-server my-kafka:9092 \
--partitions 3 \
--topic address
Created topic address.

--bootstrap-server my-kafka:9092 \
--partitions 3 \
--topic order
Created topic order.

--bootstrap-server my-kafka:9092 \
--partitions 3 \
--topic order_join
~~~

- 소스

```java
public class KStreamJoinKTable {
    private static String APPLICATION_NAME = "order-join-application";
    private static String BOOTSTRAP_SERVER = "my-kafka:9092";
    private static String ADDRESS_TABLE = "address";
    private static String ORDER_STREAM = "order";
    private static String ORDER_JOIN_STREAM = "order_join";

    public static void main(String[] args) {
        Properties props = new Properties();
        props.put(StreamsConfig.APPLICATION_ID_CONFIG, APPLICATION_NAME);
        props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVER);
        props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());
        props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());

        StreamsBuilder builder = new StreamsBuilder();
        // 소스 프로세서
        KTable<String, String> addressTable = builder.table(ADDRESS_TABLE);
        KStream<String, String> orderStream = builder.stream(ORDER_STREAM);

        // 스트림 프로세서
        orderStream.join(addressTable,
                (order, address) -> order + " send to " + address)
                .to(ORDER_JOIN_STREAM);

        KafkaStreams streams = new KafkaStreams(builder.build(), props);
        streams.start();
    }
}

```

## GlobalKTable과 KStream을 Join()
- order 토픽과 address 토픽은 코파티셔닝되어있으므로 KStream, KTable로 조인할 수 있었다.
- 파티션 개수가 다른 경우 조인
    - 리파티셔닝 수행 후 코파티셔닝이 된 상태로 조인
    - KTable로 사용하는 토픽을 GlobalKTable로 선언하여 사용