---
layout: post
title:  "대규모시스텀 설계 기초"
date:   2023-08-23 23:20:21 +0900
categories: book
---

> 가상 면접 사례로 배우는 대규모 시스템 설계 기초

## 데이터 베이스 처리
> 웹/모바일 트래픽 처리 서버와 디비서버를 분리하면 각각 독립적으로 확장 가능

### 어떤 디비 선택?
1. RDBMS
2. NoSQL
    - 낮은 응답 지연시간이 요구됨
    - 다루는 데이터가 비정형이라 관계형이 아님
    - 데이터를 직렬화 역직렬화 할 수 있기만 하면 됨
    - 아주 많은 양의 데이터를 저장할 필요가 있음


### 수직 vs 수평
로드벨런서
- 사용자는 로드밸러서의 공개IP주소로 접속한다. => 웹 서버는 클라이언트의 접속을 직접 처리 X
- 서버를 추가함으로써 로드밸러서가 부하분산을 진행하여 서버 수를 증가시켜도 OK

`디비라면?`
다중화: master-slave 구조로 원본은 마스터 사본은 슬레이브에 저장한다.
변경 연산은 마스터에서 처리되지만, 읽기 연산은 서버들로 분산처리하여 실행된다.
가용성 up -> 데이터들을 여러 지역에 복제하므로써 장애 발생 시 다른 서버에서 가져올 수 있다.

디비에 부하를 줄일려면 ? `캐시`

<hr>

## 캐시
> 캐시는 값비싼 연산 결과나 자주 참조되는 데이터를 메모리안에 두고, 뒤이은 요청이 보다 빨리 처리될 수 있도록 하는 저장소.

캐시계층
- 잠시 보관되는 곳으로 데이터 베이스보다 빠르다.
- 디비의 부하를 줄일 수 있다.
- 웹서버 -> 캐시 -> 디비 

유의사항 
1. 데이터 갱신은 자주 일어나지 않지만, 참조는 빈번하게 일어날 때 고려해보자
2. 캐시는 데이터를 휘발성 메모리에 두기때문에, 영속적으로 저장하는 것은 바람직하지 않다.
3. 만료는 어떻게 되는가, 너무 길면 원본과 차이가 있을 수 있고, 짧으면 디비를 자주 조회할 것이다.
4. 저장소의 원본을 갱신하는 연산과 캐시를 갱신하는 연산이 단일 트랜잭션이 아니라면 일관성이 깨질 수 있다.
5. 장애시? 캐시 서버를 한 대만 둔다면 장애가 발생할 수 있다. 캐시를 여러 분산으로 처리해야한다.
6. 데이터 방출 정책? 캐시가 꽉 차면 추가로 캐시에 데이터를 넣어야할 경우 기존 데이터를 내보내야한다. LRU

`CDN`
> CDN은 정적 컨텐츠를 전송하는데 쓰이지만, 지리적으로 분산된 서버의 네트워크이다.

동작과정
1. 사용자가 웹사이트 방문
2. 사용자에가 가장 가까운 CDN 서버가 정적 콘텐츠로 전달
3. CDN서버에 이미지가 없으면 원본서버에서 가져옴 (오래걸림)
4. CDN 전달

고려사항 
- 비용: 사업자에 의해 운영되기 때문에 데이터 전송량에 따라 요금이 듬, 자주 사용되지 않는 것들은 빼는 것을 고려
- 적절한 만료시간 설정: 길면 컨텐츠의 신선도가 떨어지고, 짧으면 원본서버에 빈번히 접속해야함
- 장애 대응: CDN이 죽었을 경우 웹은 어떻게 처리해야할지 
    - 컨텐츠 서비스 무효화

<hr>

현재까지 구조

정적 컨텐츠는 웹서버에서 서비스하지 않고 CDN을 통해 제공, 캐시가 디비의 부하를 줄여준다.

![구조](https://github.com/HWANGJEONGHYEON1/HWANGJEONGHYEON1.github.io/assets/43225288/150b8c8d-27fc-4190-a0fe-ea5487af0962)

<hr>

## 시스템 설계
요구사항 파악
- 구체적 어떤 기능을 만들어야할까
- 제품의 사용자수는?
- 주라 사용하는 기술 스택은?

### 예제
> 뉴스 피드 시스템을 설계

모웹과 웹앱 중 어느것을 지원해야하나? 둘 다?
<b>둘다</b>
가장 중요한 기능은?
<b>새로운 포스터를 올리고 다른 친구의 뉴스피드를 볼 수 있어야한다</b>
시간 역순으로 정렬되어야하나? 정렬기준이 있나? 친구의 포스트가 가장 가깝게 보여야하나?
<b>시간 역순으로</b>
사용자는 팔로우 수가 최대 몇명인가? 트래픽 수는 어느정도인가?
<b>5000 일간 천만명</b>
이미지나 비디오 같은 것도 올려야하나
<b>지원해야함</b>

개략적인 플로우
1. 피드 발행
    - 사용자가 포스트를 올리면 데이터가 캐시 및 디비에 저장되고 사용자 친구에게 보여진다.

2. 피드 생성(조회)
    - 어떤 사용자의 뉴스피드는 해당 사용자의 친구들의 포스트를 시간 역순으로 정렬 

![구조](https://github.com/HWANGJEONGHYEON1/HWANGJEONGHYEON1.github.io/assets/43225288/94f97cb6-d8d1-40e5-8021-4b0e1f6ce5c3)


발행에 대한 상세 설계
![상세](https://github.com/HWANGJEONGHYEON1/HWANGJEONGHYEON1.github.io/assets/43225288/32e8c417-f0a3-47a9-82e6-6f5cb451a583)

### 처리율 제한 설계
> API 요청 횟수가 제한 장치에 정의된 임계치를 넘어서면 추가로 도달한 모든 호출은 처리가 중단된다.

예)
어떤 종류의 처리율 제한장치인가? 클라이언트? 서버?
`서버측 API를 위한 장치`
어떤 기준으로 API 제어해야하나 ? 사용자 ID, IP?
`다양한 형태의 제어규칙을 통해 유연한 시스템`
시스템 규모는?
`대규모`
분산환경에서 작동해야하나?
`yes`
사용자에게 제한된 사실을 명시해야하나?
`yes`

요구사항 요약
- 설정된 처리율을 넘어서면 제한
- 낮은 응답시간을 줘야함
- 분산형 처리율 제한
- 예외처리: 요청이 제한되었을 때 사용자에게 적시
- 제한장치가 장애가나도 서비스에 영향을 주면 안됨

`토큰 버킷 알고리즘`
- 토큰 버킷은 지정된 용량을 갖는 컨테이너
- 요청에 대해 토큰이 주기적으로 채워짐
- 꽉 찼다면 토큰은 채워지지 않는다.
- 충분한 토큰이 없는경우 요청은 버려진다.
- 예시
    1. 4개의 토큰 존재
    2. 1개의 요청 1개 토큰이 제거
    3. 현재 토큰버킷은 3개의 토큰이남음
    4. 4번의 요청이 들어옴 3개의 토큰 사라짐 -> 요청 응답 나감
        - 1개의 요청은 버려짐
    5. 몇초 후 4개의 토큰 다시 생성됨
- API 별 토큰 버킷을 생성
    - 사용자 마다 하루에 1번 포스팅 -> 1개의 토큰버킷
    - 친구는 150명까지 생성 -> 토큰버킷
- 장점
    - 구현이 쉽다.
    - 메모리 사용 효율적
    - 짧은 시간에 트래픽도 처리가능
- 단점
    - 토큰 공급률, 버킷 크기 값을 적절하게 튜닝하는것이 까다로움


`누출 버킷 알고리즘`
- FIFO 큐로 구현
- 요청이오면 큐가 가득차있는지?
- 가득 차 있으면 새 요청은 버림
- 지정된 시간마다 큐에서 요청을 꺼내어 처리
- 필요 파라미터
    1. 버킷크기: 큐 사이즈, 큐에서 처리될 항목
    2. 처리율: 지정된 시간마다 몇 개의 항목을 처리할지 결정
- 장점
    - 큐의 크기가 제한되어있어 메모리 사용량에 적절
    - 고정된 처리율을 갖고 있기 때문에 안정적 출력이 필요한 경우 적합
- 단점
    - 단시간에 몰리는 트래픽인 경우 오래된 요청은 쌓이게됨, 처리되지 못할 시 최신 요청은 버려짐
    - 파라미터 값을 적절하게 튜닝하는것이 까다로움

`미들웨어 : 레디스`
- 메모리상에서 동작하는 캐시가 바람직하며, 처리시간도 빠르다.
- INCR, EXPIRE 지원
    - INCR : 메모리에 저장된 카운트 값 + 1
    - EXPIRE : 카운터에 타임우앗 값을 설정한다. 설정된 시간이 지나면 카운터는 삭제
- 동작원리
    1. clinet -> redis
    2. 레디스의 카운트를 가져와 한도에 도달했는지 체크, 도달되었다면 요청 버림


`경쟁조건`
1. 레디스에서 값을 읽는다.
2. count + 1 값이 임계치를 넘는지 확인
3. 넘지 않는다면 1 증가
4. 동시에 2개의 요청 레디스의 카운트는 4
    - 동시에 접근했기에 각각 하나의 + 1이되어 5가 될것이다.
    - 레디스는 락을 사용하여 가능하다.

`동기화 이슈`
1. 고정세션을 통해 같은 클라이언트로부터의 요청은 항상 같은 처리율 제한 장치로 보낼 수 있다.
    - 이 방법은 규모면에서 확장가능하지 않고 유연하지도 않다.
2. 레디스 클러스터 같은 중앙 집중형을 사용하여 반영하자. 또는 카프카

<hr>

## 분산시스템을 위함 유일 ID 생성기 설계
> auto_incremenet 기본 키를 쓰면된다? 분산환경에서는 디비서버 한대로는 요구를 감당할 수 없고 지연현상이 매우 클것이다.

설계
1. ID는 유일 해야한다.
2. 숫자로만 구성되어한다.
3. 64비트로 표현될 수 있는 값이어야한다.
4. 밥급날짜에 따라 정렬이 가능하다.
5. 초당 만 개의 아이디를 만들 수 있어야한다.

개략적 설계
- 다중 마스터 복제
    - 디비의 auto_increment를 활용하되, 다음 id를 1만큼 증가시켜 얻는것이 아니라 서버의 수만큼 중가시킨다.
    - 단점: 여러 디비센터에 규모를 늘리기 어렵다. 유일성은 보장되나 시간 흐름에 맞추기 어렵다. 서버 추가 삭제할 때 잘 동작하게 하는것이 어렵다.
- UUID
    - 장점: 단순하다. 규모 확장이 쉽다.
    - 단점: 정렬 어렵다. 128비트로 길다. 숫자가 아닌 값이 포함될 수 있다.
- 트위터 스노 플레이크
    - ID를 바로 생성하는것이 아닌 생성하는 ID의 구조를 여러번 분할 -> 타임스탬프 + 데이터센터ID + 서버ID + 일련번호

<hr>

## URL 단축기 설계

설계
1. 매일 1억계의 단축 URL 생성
2. 초당 쓰기 연산 : 1억 / 24 / 3600 = 1160
3. 10년 운영하면 너무 많은 데이터를 보관해야함
4. 축약전의 평균 URL 길이는 100

endpoint

url 단축용 api
POST /api/v1/shorten
param: longUrl, return 단축Url
url 리다이렉션용
GET /api/v1/shortUrl

과정
1. 단축 url -> 단축 도메인 서버 -> 301 응답, Location: 원문 url -> 원래 URL 서버
    - 301 Permanantly Moved: HTTP 요청의 처리 책임이 영구적으로 Location 헤더에 반환된 URL로 이전되었다는 응답. 브라우저는 이 응답을 캐싱, 추후 똑같은 url 요청이 왔을 때 캐싱된 url로 전송
        - 서버 부하를 줄일 수 있다.
    - 302 Found: 일시적으로 Location 헤더에 지정하는 URL에 의해 처리되어야한다는 응답.
        - 트래픽 분석이 중요할 때는 이것, 클릭 발생률 등.


<hr>

## 알림시스템
> 하루에 100만건 이상 알림을 처리하는 확장성 높은 시스템 구축

예)
어떤 종류의 알림을 지원?
`푸시, SMS, 이메일`
실시간 지원?
`알림은 가능한 빨리 지원하되, 약간의 지연현상이 발생할 수 있음`
어떤 종류의 단말?
`ios, aos, pc`
푸시 메시지는 누가 작업하나?
`클라이언트 또는 서버 스케쥴링`
사용자는 알림을 끌 수 있나?
`yes`
하루에 몇 건의 알람을 보내는가?
`천만 건의 모바일 푸시, 100만 건의 sms, 5백만건 이하의 이메일`

설계
1. API 호출하여 알림 서버로 알림을 보냄
2. 알림서버는 사용자정보, 단말 토큰, 알림 설정 같은 메타데이터를 캐시나 디비로 가져온다.
3. 알림서버는 전송할 알림에 맞는 이벤트를 만들어 해당 이벤트를 위한 큐에 넣는다.
4. 작업 서버는 메시지 큐에서 알림 이벤트를 꺼냄
5. 작업 서버는 알림을 각 역할에 맞게 서비스로 보냄

안정성
- 데이터 유실 가능성 -> 데이터 베이스에 기록하기 위해 실패시 재처리 추가
- 중복
    - 보내야할 알림이 도착하면 그 이벤트 ID를 검사하여 중복인지 체크


![구조](https://github.com/HWANGJEONGHYEON1/HWANGJEONGHYEON1.github.io/assets/43225288/738d1639-6d99-4e77-9e93-cf43571c0b2f)

- 알림서버에 인증과 전송률 제한 추가
- 전송실패에 대한 재시도 기능 추가, 실패한 알림은 다시 큐에 넣어 지정된 횟수만큼 재시도
- 모니터링 시스템 추가 


<hr>

## 채팅 설계

설계
1. 응답지연이 낮은 일대일 채팅 기능
2. 100명 까지 그룹 채팅 기능
3. 사용자의 접속상태 표시 기능
4. 하나의 계정으로 여러개의 단말 지원기능
5. 푸시알림

고려사항
1. 폴링
    - 클라이언트가 주기적으로 서버에게 새 메시지가 있냐고 물어보는 방법
    - 폴링비용은 폴링을 자주 할수록 올라간다. 서버 자원이 불필요하게 낭비
2. 롱 폴링
    - 폴링을 하면서 새 메시지가 응답이 오거나 또는 타임아웃 될 때까지 연결을 유지 
    - 서버입장에서는 클라이언트가 연결을 했는지 안했는지 알 수가 없다.
3. 웹 소켓
    - 웹소켓 서버가 client에게 비동기 메시지를 보낼 때 쓰는 기법
    - 웹 소켓 연결은 항구적이며 양방향이다.
    - 처음에는 HTTP 연결이지만 특정 핸드쉐이크 절차를 거쳐 웹소켓 연결로 업그레이드 된다.

저장소
- RDB ? NoSql?
- 채팅 시스템이 다루는 데이터
    1. 설정, 친구, 프로필, 목록 => RDB
    2. 채팅 이력 => NoSql
        - 수평적 확장이 용이하다. 데이터 접근 레이턴시가 낮다.

메시지 ID
- 값은 고유해야한다.
- 정렬 가능해야한다. 새로운 ID는 이전의 ID보다 커야한다.
    - 스노플레이크

단말 동기화
- pc: cur_max_message_id = 20, app: cur_max_message_id = 30 일 경우 
- 채팅 서버의 세션은 pc, app에 대해 세션이 2개
- 각 단말은 cur_max_message_id 라는 변수로 유지된다. 가장 최신 메시지의 ID를 추적하는 용도
    - 수신자 ID가 현재 로그인한 사용자와 같다.
    - 키 값 저장소에 보관된 메시지로, ID가 cur_max_message_id 보다 크다.

소규모 그룹 채팅 흐름
- 사용자가 그룹 채팅방에서 메시지를 보냈을 때 다른 사용자들의 메시지 동기화 큐에 복사된다.

접속상태 표시
- 사용자 로그인
    - 클라이언트와 실시간 서비스 사이에 웹소켓이 맺어지고나면 접속상태 서버는 A의 상태와 last_active_at 타임스탬프 값을 키값 저장소에 젖아한다. 상태는 Online
- 로그아웃
    - 상태는 offine
- 접속 장애
    - 인터넷 문제로 인해 맺어진 소켓이 끊어진다면 문제가있다.
    - 이럴 경우 hearbeat 통신을 통해 이 서버로 계속 확인 요청을 보낸다. 요청에 대한 응답이 없을 시 로그아웃

생각거리
1. 종단 간 암호화: 발신자 또는 수신자를 제외한 이외는 아무도 볼 수 없게 만들어야함
2. 로딩속도: 사용가자 너무 많아지면 느려짐, 분산 네트워크 구현
3. 오류처리: 서버 하나가 죽으면 주키퍼 같은 것을 구동하여 클라이언트에게 새로운 서버를 배정한다.

<hr>


