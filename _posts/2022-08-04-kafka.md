---
layout: post
title:  "kafka 기초 "
date:   2022-08-04 16:20:21 +0900
categories: kafka
---

# 카프카 기초

## Kafka feature

|kafka producer| kafka| kafka consumer|
|Source App| topic1, topic2 .. | TargetApplication|

## Kafka topic
- 데이터가 들어갈 수 있는 공간.
- 여러개의 토픽을 생산할 수 있음.
- 이름을 가질 수 있음
- 토픽별로 여러개의 파티션이 있다.
    - 0번부터 시작한다.
- consumer가 데이터를 가져가지만, 데이터는 삭제되지 않는다.
- 파티션의 삭제가 되는 시점은 최대 record 보존시간
- 키를 지정하지 않으면 라운드로빈으로 파티션이 지정됨
- 키를 지정하면 특정 파티션에 할당
- `파티션을 늘릴 수 있지만, 줄일 수 없다.(유의)`

## broker
- 카프카가 설치되어있는 서버단위
    - 보통 3개 이상 구성

## replication
- 파티션 복제를 뜻함
- replication 1 -> partition 1
- replication 2 -> 원본 1개 복제본 1개

## 파티셔너
- 프로듀서가 데이터보내면, 무조건 파티셔너를 통해 브로커로 데이터가 전송됨
- 어떤 파티션에 전송할지 설정
- message-key
    - 파티셔너에 의해 해시값이 결정됨

## lag
- 프로듀셔가 데이터를 넣는것이 컨슈머에서 데이터를 가져가는것보다 속도가 빠르다면 오프셋간의 차이가 발생
- 주로 컨슈머 상태에대해 볼때 확인
- 프로듀서가 넣은 데이터의 오프셋과 컨슈머가 가져가는 데이터의 오프셋 차이를 기반으로 함
- 렉은 여러개 존재할 수 있다(-> 파티션이 여러개 있기 때문에)

## 버로우
- 멀티 카프카 클러스터 lag을 모니터링 가능
- 슬라이딩 윈도으를 통해 컨슈머 스테이터스를 확인가능

## rabbitMQ, resdis Queue, kafka 차이점
- 메시지 브로커는 앞의 둘
- 이벤트 브로커는 카프카

## 프로듀서
- 데이터를 생산하는 역할(카프카에 보내는 역할)
- kafka topic에 셍신 
- 데이터 적재
- role
    - 토픽에 해당하는 메시지를 생성
    - 특정 토픽으로 데이터를 publish
    - 처리 실패/재시도

product는 토피엑 메시지를 보냄
성능 로드벨런싱 가용성 업무 정합성 등을 고려하여 어떤 브로커의 파티션으로 메시지를 보내야할지 전략적으로 결정

컨슈머
poll() 메소드를 통해 주기적으로 브로커의 토픽 파티션에서 메시지를 가져옴.

auto.offset.reset
메시지를 성공적으로 가져왔으면 commit을 통해 _consumer_offset에 다음에 읽을 offset위치를 기재함
가장 오래된 처음 offset부터 가져올것인지, 가장 최근인 마지막 offset부터 가져올 것인지 

객체를 send
객체 직렬화 (serializer) byte code

과정
Producer -> send -> serializer -> partioner(어느 파티션으로 보낼지?) -> topic -> sender -> 카프카 브로커

(Producer -> 객체를 바이트 어레이로 변경 -> 브로커 -> 바이트어레이 저장 -> 컨슈머 -> 바이트어레이 역직렬화)

Linger.ms를 설정하여 레코드 배치를 가져갈 때 일정시간 대기하여 Record Batch에 메시지를 보다 많이 채울 수 있도록 적용 

전송 룰 
1. 최대 한번전송 (at most once)
2. 적어도 한번 전송 (at least once)
    1. 중복이 될 수 있음 
3. 정확히 한번 전송(exactly once)
    1. 중복없이 전송: 프로듀서의 리트라이 시 중복제거
    2. 트랜잭션 기반 전송

Idempotence
- 프로듀서는 브로커로부터 ack을 받은 다음에 다음 메시지 전송하되, Producer ID와 메시지 seq를 헤더에 저장하여 전송
- 메시지 seq는 메시지의 고유 seq 번호, 0부터 시작하여 순차적으로 증가, producerID는 기동 시마다 생성
- 브로커에서 메시지 seq가 중복될 경우 이를 메시지 로그에 기록하지 않고 ack만 전송
- 브로커는 프로듀서가 보낸 메시지의 seq가 브로커가 가지고 있는 메시지의 seq보다 1만큼 큰 경우에 브로커에 저장
- 설정방법
    - enable.idempotence = true
    - Asks = all
    - Retries > 0
    - max.in.flight.requests.per.connection 1 ~5
- 전송순서 유지
    - 프로듀서에서 생성된 메시지 배치 max.in.flight.requests.per.connection 만큼 여러개의 배치들이 전송됨, 브로커는 메시지 배치를 처리시 write 된 마지막 배치의 seq + 1 이 오지않을 경우 에러 전달



메시지 전송 / 재전송 시간 파라미터
Delivery.timeout.ms >= linger.ms +. request.timeout.ms
1. max.block.ms send() 호출 시 record accumulator에 입력하지못하고 block 되는 최대 초과시간 -> 시간지나면 timeout
2. request.timeout.ms : 전송에 걸리는 최대시간, 전송 재시도 대기시간 제외, 초과 시 retry 또는 타임아웃
3. retry.backoff.ms : 전송 재 시도를 위한 대기시간
4. Delivery.timeout.ms : 메시지 전송에 허용된 최대 시간

파티셔너 
프로듀서를 통해 전송시 파티셔너를 통해 토픽의 어떤 파티션으로 전송되어야할지 판단
Key 값이 없는 경우 라운드로빈, 스티키 파티션등의 파티션 전략이 선택되어 파티션 별로 메시지가 전송될 수 있음
토픽이 여러개의 파티션을 가질 때 전송순서가 보장되지 않은채로 컨슈머에서 읽힐 수 있음

특정 키값을 가지는 메시지는 특정 파티션으로 고정되어 전송됨.

라운드 로빈 - kafka 2.4 이전 버전 기본 전략
- 최대한 메시지를 파티션에 균일하게 분배하려는 전략 메시지배치를 순차적으로 다른 파티션으로 전송함
- Batch.size.linger.ms 설정에 정해놓은 값에 따라 전달 가능
- 메시지가 배치 데이터를 빨리 채우지못하면, 전송이 늦어지거나 배치를 다 채우지못하고 전송하면서 성능이 떨어짐
스트키 파티셔닝 - 2.4부터 파티션 분배 기본전략
- 라운드로빈의 향상
- 특정 파티션으로 전송되는 하나의 배치에 메시지를 빠르게 먼저 채워서 보내는 방식

컨슈머 poll() 동작과정
1. LinkeQueue에 데이터가 있는 경우 Fetcher는 데이터를 가져와 반환
2. ConsumerNetworkClient는 비동기로 계속 데이터 가져와  LinkedQueue에 저장
3. LinkedQueue에 데이터가 없을 경우 1000ms까지 브로커에 메시지 요청 

Fetcher
* fetch.min.bytes = 16384 => 레코드들을 읽어들이는 최소 바이트, 이 속성에 새로운 메시지가 쌓일때까지 전송하지 않음
* fetch.max.wait.ms = 500 => 메시지가 쌓일때까지 최대 대기시간 
```java

public class Producer {
    main() {
        Properties configs = new Properties();
        configs.put("bootstrap.servers", "localhost:9092"); 
        configs.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        configs.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

        KafkaProducer<String, String> producer = new KafkaProducer<String, String>(configs);
        // 키없이 보냄.
        ProducerRecord record = new ProducerRecord<String, String> ("click_log", "login");
        // 키를 같이 보내고싶다면 
        ProducerRecord record = new ProducerRecord<String, String> ("click_log", 1, "login");
        producer.send(record);
        producer.close();
    }
}

```

## 컨슈머
- 데이터를 가져가도 사라지지 않는다.
- 데이터 파이프라인
- 토픽의 데이터를 가져온다.
- 폴링
- role
    - Topic의 파티션으로부터 데이터 폴링
    - 파티션 오프셋의 위치 기록 (commit)
    - 컨슈머 그룹을 통해 병렬처리

```java
public class Consumer {
    main() {
        Properties configs = new Properties();
        configs.put("bootstrap.servers", "localhost:9092"); 
        configs.put("group.id", "click_log_group"); 
        configs.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        configs.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

        KafkaConsumer<String, String> consumer = new KafkaConsumer<String, String>(configs);
        consumer.subscribe(Arrays.asList("click_log"));

        while(true) {
            ConsumerRecord<String, String> records = consumer.poll(500); // 0.5초동안 데이터가 도착하기를 기다림, 들어오지 않으면 빈 레코드 반환
            for (ConsumerRecord<String, String> record : records) {
                sout(record.value());
            }
        }

    }
}
```

## apache kafka stream
- 카프카에서 공식적으로 제공하는 라이브러리
- 스프링부트에 올려서 사용가능하다
- 장점
    - 카프카와 완벽호환
    - 스케쥴링 도구가 필요없다.
    - 스파크 스트리밍을 사용하면 이벤트 데이터 애플리케이션을 만든다.
        - 클러스터 관리자나 매니저를 구축해야한다.
    - 스트림즈DSL 사용(이벤트기반 다양한 기능들을 제공), 
    - 로컬 상태저장소를 사용한다.
        - 실시간 방식
            - 비상태 기반처리
                - 데이터들어오는 족족 바로 프로듀스 (유실 중복 없음)
            - 상태기반 처리 

<hr>

# 간단 정리

* 브로커: 카프카 클라이언트와 데이터를 주고 받기위해 사용 되는 주체, 데이터를 분산 저장하여 장애가 발생하더라도 안전하게 사용할 수 있도록 도와줌
    - 하나의 서버에는 한 개의 브로커 프로세스가 실행
    - 컨트롤러: 다수 브로커중 1개가 컨트롤러 역할을함, 컨트롤러는 다른 브로커들의 상태를 계속 체크하고 브로커가 클러스터에서 빠지는 경우 해당 브로커에 존재하는 리더 파티션을 재분배, 컨트롤러 역할을 하는 브로커에 장애가 생기면 다른 브로커가 그 역할을 이어감
    - 로그 세그먼트로 파일이 저장 삭제가 된다.
    - 역할
        1. 컨슈머 오프셋 저장: 컨슈머 그룹은 토픽이 특정 파티션으로부터 데이터를 가져가서 처리하고 이 파티션이 어느 레코드까지 가져갔는지 확인하기 위해 오프셋을 커밋, 커밋한 오프셋은 _consumer_offsets 토픽에 저장, 여기에 저장된 오프셋을 토대로 컨슈머그룹은 다음 레코드를 가져가서 처리한다.
        2. 그룹 코디네이터: 컨슈머 그룹의 상태를 체크하고 파티션을 컨슈머와 매칭되도록 분배하는 역할
        3. 복제: 클러스터로 묶인 브로커 중 일부 장애가 발생하더라도, 데이터를 유실하지않고 안전하게 사용하기 위함. 파티션 단위로 복제가 이루어짐


* 토픽: 카프카에서 데이터를 구분하기 위해 사용되는 단위, 토픽은 1개 이상의 파티션을 소유하고 있다.
    - 먼저 들어간 레코드는 컨슈머가 먼저 가져가개됨, 하지만 데이터는 삭제하지 않음
* 파티션: 프로듀서가 보낸 데이터들이 저장되는대 이 데이터를 `레코드`라고 부름
            
# 참고 실습 
- https://github.com/HWANGJEONGHYEON1/Kafka_Flink_Integration
- https://www.youtube.com/watch?v=SqVfCyfCJqw
- https://www.youtube.com/watch?v=0Ssx7jJJADI&t=138s