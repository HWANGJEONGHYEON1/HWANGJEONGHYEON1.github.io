---
layout: post
title:  "아파치 카프카 스터디 - 2"
date:   2023-01-09 12:20:21 +0900
categories: kafka, spring
---

> 아프치 카프카 애플리케이션 프로그래밍 스터디 - 2


# 목표?
- 회사에서 대용량 데이터를 처리하는것에 있어, 카프카를 사용하고 있으므로, 제대로된 학습을 통해 원하는 처리를 할 수 있도록 한다.


# 카프카 기본개념 

## 카프카 브로커, 클러스터, 주키퍼
- 브로커: 카프카 클라이언트와 데이터를 주고받기 위해 사용하는 주체이자, 데이터를 분산 저장하여 장애가 발생하더라도 안전하게 사용할 수 있도록 도와주는 어플리케이션
    1. 하나의 서버에는 한 개의 카프카 브로커 프로세서가 실행
    2. 안전하게 보관되고 처리하기 위해서 3대 이상의 브로커 서버를 1개의 클러스터로 묶어 운영
    3. 카프카 클러스터로 묶인 브로커들은 프로듀서가 보낸 데이터들을 안전하게 분산저장 및 데이터 복제 역할을 수행
    - 프로듀서로부터 데이터를 전달받으면 카프카 브로커는 프로듀서가 요청한 토픽의 파티션에 데이터를 저장하고 컨슈머가 데이터를 요청하면 파티션에 저장된 데이터를 전달한다. 그러면 전달된 데이터는 `파일시스템에 저장된다`(/tmp/kafka-logs)
        - config/server.properties의 log.dir 옵션에 정의한 디렉토리에 데이터를 저장, 토픽 이름과 파티션 번호의 조합으로 하위 디렉토리를 생성하여 데이터 저장
        - log에는 메시지와 메타데이터를 저장. index는 메시지의 오프셋을 인덱싱한 정보를 담은 파일이다.
        - timeindex 파일에는 메시지에 포함된 타임스탬프 값을 기준으로 인덱싱한 정보가 담겨있다. -> 타임스탬프는 브로커가 적재한 데이터를 삭제하거나 압축하는데 사용한다.
    - 카프카는 메모리나 데이터베이스에 저장하지 않으며 따로 캐시메모리를 구현하여 사용하지도 않는다. 파일 시스템에 저장히가 때문에 파일 입출력으로 인하여 속도 이슈가 발생하지 않을까 생각할 수 있지만, 페이지 캐시를 사용하여 디스크 입출력 속도를 높여 해결했다.
        - 페이지캐시? OS에서 파일 입출력의 성능향상을 위해 만들어놓은 메모리 영역 
- 데이터 복제
    - 카프카를 장애허용 시스템으로 동작하도록 하는 원동력
    - 복제의 이유는 클러스터로 묶인 브로커 중 일부에 장애가 발생하더라도 데이터를 유실하지 않고 안전하게 사용하기 위함
    - 카프카의 데이터복제는 파티션 단위로 이루어진다.
    - 토픽을 생성할 때 파티션의 복제 개수도 같이 설정되는데 직접 옵션을 선택하지 않으면 브로커에 설정된 옵션값을 따라간다.
        - 복제 개수의 최솟값은 1이고 최댓값은 브로커의 개수 만큼 설정할 수 있다.
    - 복제된 파티션은 리더와 팔로워로 구성된다.
        - 프로듀서 또는 컨슈머와 직접 통신하는 파티션을 리더, 나머지는 복제 데이터를 가진 팔로워라고 부른다.   
        - `복제`
            - 팔로워 파티션은 리더의 오프셋을 확인하여 현재의 파티션에 저장한다.
            - 파티션 복제로인해 나머지 파티션도 데이터가 저장되므로써 저장 용량이 증가한다는 단점이 있다.
            - 운영을 할 때는 2 이상의 복제 개수를 정하는 것이 중요하다. => 장애의 대비
- 컨트롤러
    - 클러스터의 다수 브로커 중 한 대가 컨트롤러 역할을 한다.
    - 컨트롤러는 다른 클러스터들의 상태를 체크하고 브로커가 클러스터에서 빠지는 경우에는 해당 브로커에 존재하는 리더 파티션을 재분배한다.
    - 카프카는 지속적을 데이터를 처리해야 하므로 브로커의 상태가 비정상적이라면 빠르게 클러스터에서 빼내는 것이 중요하다.
- 컨슈머 오프셋 저장
    - 토픽이 특정 파티션으로 데이터를 가져가서 처리하고 이 파티션의 어느 레코드까지 가져갔는지 확인하기 위하여 오프셋을 확인한다.
    - 커밋한 오프셋은 _consumer_offset 토픽에 저장한다. 저정된 오프셋을 토대로 컨슈머 그룹은 다음 레코드를 처리
- 코디네이터
    - 클러스터의 다수 브로커 중 한대는 코디네이터의 역할을 수행한다.
    - 컨슈머 그룹 상태를 체크하고 파티션 컨슈머와 매칭되도록 분배하는 역할
    - `리벨런싱`
        - 컨슈머가 컨슈머 그룹에서 빠지면 매칭되지 않은 파티션을 정상 동작하는 컨슈머로 할당하여 끊임없이 데이터가 처리되도록 도와준다


## 토픽 파티션
- `토픽`은 카프카에서 데이터를 구분하기 위해 사용되는 단위
    - 1개 이상의 `파티션`을 소유하고 있다. 파티션에는 프로듀서가 보낸 데이터들이 들어가 있는대, 이 데이터를 `레코드`라고 부른다.
- `파티션`은 카프카의 병렬처리의 핵심으로서 그룹으로 묶인 컨슈머들이 레코드를 병렬로 처리할 수 있도록 매칭된다.
    - 컨슈머의 처리량이 한정된 상황에서 많은 레코드를 병렬로 처리하기 가장 좋은 방법은 컨슈머의 개수를 늘려 스케일 아웃을 하는 것이다.
- 토픽이름 제약조건
    - 빈 문자열 토픽이름 X
    - 토픽 이름은 마침표 하나 또는 마침표둘(..)로 생성될 수 없다.
    - 글자 수 249미만
    - 마침표와 언더바가 들어가면 안된다.
    - 예시
        - 환경명.팀-명.appname.message-type
        - 프로젝트명.서비스명.환경.이벤트명
        - ...

## 레코드
- 레코드는 타임스탬프, 메시지 키, 값, 오프셋, 헤더로 구성
- 프로듀서가 생성한 레코드가 브로커로 전송되면 오프셋과 타임스탬프가 지정되어 저장된다.
- 브로커에 한번 적재된 레코드는 수정할 수 없고, 로그 리텐션 기간 또는 용량에 따라 삭제된다.
- 타임스탬프는 프로듀서에서 해당 레코드가 생성된 시점의 유닉스 타입이 설정된다. -> 언제 생성되었는지 확인가능
- 메시지 키는 값을 순서대로 처리하거나, 메시지 값의 종류를 나타내기 위해 사용된다.
    - 메시지 키를 사용하면 프로듀서가 토픽에 레코드를 전송할 때 메시지 키의 해시값을 토대로 파티션을 지정하게 된다.
    - 동일한 키라면 동일 파티션에 들어간다. 어느 파티션에 지정될지 알 수없고, 파티션 개수가 변경되면 메시키 키와 파티션 매칭이달라지게 되므로 주의해야한다.
    - 메시지키를 선언하지 않으면 키가 null로 설정된 레코드는 프로듀서 기본 설정 파티셔너에 따라 파티션에 분배되어 적재

## 프로듀서 어플리케이션
- image.png
- 중요개념
    - 카프카 브로커로 데이터를 전송할 때 내부적으로 파티셔너, 배치 생성 단계를 거친다.
    - 전송하고자 하는 데이터는 ProducerRecord 클래스를 통해 인스턴스를 생성했지만, ProducerRecord 인스턴스를 생성 필수 파라미터인 토픽과 메시지 값만 설정하였다.
    - KafkaProducer send()를 호출하면 ProducerRecord는 파티셔너에서 토픽의 어느 파티션으로 전송될지 결정된다. ProducerRecord를 생성할 때 파티셔너를 따로 설정하지 않으면 DefaultPartitioner로 설정되어 파티션이 정해진다.
    - 파티셔너에 의해 구분된 레코드는 데이터를 전송하기 전에 어큐뮬레이터에 데이터를 버퍼로 쌓아놓고 발송
    - 버퍼에 쌓인 데이터는 배치로 묶어 전송함으로써 카프카의 프로듀서 처리량을 향상시키는 데에 도움을준다.
    - 프로듀서 API
        - UniformStickyPartitioner는 프로듀서 동작에 특화되어 높은 처리량과 낮은 리소스 사용률을 가진다.
            - 2.4.0 이전에는 RoundRobiunPartitioner가 기본 파티셔너로 설정되어있다.
            - RoundRobiunPartitioner은 들어오는 대로 순회하며 전송하기 때문에 들어오는 배치로 묶이는 빈도가 적다.
    - 주요 옵션 필수옵션
        - bootstrap.server: 프로듀서가 데이터를 전송할 대상 카프카 클러스터에 속한 브로커의 호스트 이름:포트를 1개 이상 작성한다.
        - key, value.serializer: 레코드의 키 값을 직렬화하는 클래스를 지정한다.
    - 선택 옵션
        - kafka 공식문서를 확인하자(https://kafka.apache.org/documentation/)
    


```java
public class SimpleProducer {

    private final static Logger logger = LoggerFactory.getLogger(SimpleProducer.class);
    private final static String TOPIC_NAME = "test";
    private final static String BOOTSTRAP_SERVER = "my-kafka:9092";

    public static void main(String[] args) {
        Properties configs = new Properties();
        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVER);
        configs.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        configs.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
//        configs.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, CustomPartitioner.class);

        KafkaProducer<String, String> producer = new KafkaProducer<>(configs);
        String messageValue = "testMessage";
        ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, messageValue);
        // 즉시 send를 하는게 아니라 프로듀서 내부에 가지고 있다가 배치형태로 묶어서 브로커에 전송한다. => 배치전송
        producer.send(record); 
        logger.info("{}", record);

        // 내부 버퍼에 가지고 있던 레코드 배치를 브로커로 전송
        producer.flush();
        producer.close();
    }
}
```