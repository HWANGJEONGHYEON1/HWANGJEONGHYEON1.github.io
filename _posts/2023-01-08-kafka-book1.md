---
layout: post
title:  "아파치 카프카 스터디 - 1"
date:   2023-01-08 18:20:21 +0900
categories: kafka, spring
---

> 아프치 카프카 애플리케이션 프로그래밍 스터디 - 1 


# 목표?
- 회사에서 대용량 데이터를 처리하는것에 있어, 카프카를 사용하고 있으므로, 제대로된 학습을 통해 원하는 처리를 할 수 있도록 한다.


## 카프카란?
- 링크드인에서 개발
- 시간이 지날수록 애플리케이션의 개수가 증가함으로써 데이터 관리가 복잡해짐 => 장애가 발생우려
- 내부 데이터 흐름을 개선하기 위해 개발
- `각각의 애플리케이션끼리 연결하여 데이터를 처리하는 것이 아니라 한 곳에 모아 처리할 수 있도록 중앙집중화`
- 카프카 내부에 저장되는 파티션 동작은 FIFO 방식의 큐 자료구조와 유사.
- 큐에서 데이터를 보내는 것이 `프로듀서`, 큐에서 데이터를 가져가는 것이 `컨슈머`
- 데이터 포맷은 제한이 없다. 직렬화, 역직렬화를 통해 ByteArray로 통신 => 자바를 지원

## 데이터레이크
- 빅 데이터를 관리하고 사용하는 측면에서 중요한 용어.
- 데이터가 모이는 저장공간
- 운영되는 서비스로부터 수집 가능한 모든 데이터를 모으는 것


## 카프카 특징
- 높은 처리량
    - 프로듀서가 브로커로 데이터를 보낼 때와 컨슈머로 데이터를 받을때 모두 묶어서 전송
    - 많은 양의 데이터를 송수신할 때 맺어지는 네트워크 비용을 절약할 수 있다.
    - 많은 양의 데이터를 묶음 단위로 처리하는 배치로 빠르게 처리할 수 있고, 실시간 로그성 데이터를 처리하는데에 적합
    - 파티션 단위를 통해 동일 목적의 데이터를 여러 파티션에 분배하고, 데이터를 병렬 처리할 수 있다.
    - 파티션 개수만큼 컨슈머 개수를 늘려 동일한 시간당 데이터 처리량을 늘리는 것
- 확장성
    - 데이터 파이프라인에서 얼마나 데이터를 들어오는지 예측하기 어렵다.
    - 가변적인 환경에서 안정적으로 확장가능하도록 설계되어있다.
    - 데이터가 적을 때 카프카 클러스터의 브로커를 최소한의 개수로 운영하다가 데이터가 많아지면 클러스터의 브로커 개수를 자연스럽게 늘려 스케일 아웃 할 수 있고, 반도래 스케일 인 할 수 있다.
- 영속성
    - 의도치 않게 프로그램이 종료되더라도, 사라지지 않는 것
    - 카프카는 전송받은 데이터를 파일 시스템에 적재한다.
    - 페이지 캐시 메모리 영역을 사용하여, 한번 읽은 내용은 메모리에 저장하였다가 다시 사용할 수 있다.
- 고가용성
    - 3개이상의 카프카 서버로 운영되는 카프카 클러스터는 일부 서버에 장애가 발생하더라도 무중단으로 안전하고 지속적으로 데이터를 처리할 수 있다.
    - 클러스터로 이루어진 카프카는 데이터의 복제를 통해 고가용성 특징을 가지게 되었다.
    - 프로듀서로 전송된 데이터를 1대의 브로커에만 저장하는것이 아니라 또 다른 브로커에도 저장한다.
- `카프카 클러스터를 3대 이상해야하는 이유`
    - 브로커 3대 중 1개의 브로커가 장애가 나더라도 지속적으로 데이터를 처리할 수 있기 때문이다.
        - min.insync.replicas 옵션보다 작은 수의 브로커가 존재할 때는 토픽에 더는 데이터를 넣을 수가 없다.


## 인스턴스에서 주키퍼 실행
- bin/zookeeper-server-start.sh -daemon config/zookeeper.properties 
    - daemon 옵션은 주키퍼를 백그라운드로 옵션으로 실행할 수 있다.
- jps -vm 
    - jps는 프로세스 상태를 보는 도구로, JVM 위에서 동작하는 주키퍼 프로세스를 확인할 수 있다.


## 토픽 생성하는 두가지 방법
1. 컨슈머 또는 프로듀서가 카프카 브로커에 생성되지 않은 토픽에 대하 데이터를 요청할 때
2. 커맨드라인 툴로 명시적으로 토픽 생성
    - 유지보수를 위해 2번째 방법이 좋다.

```
bin/kafka-topics.sh \
> --create \ 
> --bootstap-server my-kafka:9092 \ # 카프카 클러스터를 구성하는 브로커들의 IP와 PORT를 적는다. 1개와 통신하기때문에 1개만 들어갔다.
> --topic hello.kafka # 토픽 이름을 작성 명확한 이름을 지어야 유지보수하기 좋다.


bin/kafka-topics.sh \
--create \
--bootstrap-server my-kafka:9092 \
--partitions 3 \ # 파티션의 개수를 정할 수 있다.
--replication-factor 1 \ # 토픽의 파티션을 복제할 복제 개수를 적는다. 1은 사용안함 2는 사용함 파티션의 데이터는 각 브로커마다 저장된다.
--config retention.ms=172800000 \ # --config를 통해 kafka-topics.sh 명령에 포함되지 않은 추가적인 설정가능 => retention.ms는 토픽의 데이터를 유지하는 기간 2일뒤에 데이터는 삭제된다.
--topic hello.kafka.2
```

## ec2에서 카프카 브로커를 start 하고 로컬 접근 시 이슈
- config/server.properties에서 리스터를 기존에 사용하던 IP로 사용하였으나
- 현재 IP가 바뀐상태에서 하려고 하다보니 연결 에러발생
- `advertised.listeners=PLAINTEXT://${EC-2 IP}:9092` 
- 참고(https://always-kimkim.tistory.com/entry/kafka101-configuration-bootstrap-servers) 

## 토픽 생성 시 --zookeeper를 사용하는것이 아니라 bootstrap-server를 사용하는 이유 
- 카프카는 2.2 버전이후 주키퍼와 통신하는 대신 카프카를 통해 토픽과 관련된 명령을 실행할 수 있다. 주키퍼와 직접 통신하여 명령을 처리하는 것은 아키텍처의 복잡도를 높였다.

## 카프카 토픽 조회
- `bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --list` # 토픽 리스트 조회
- 카프카 클러스터의 성능이 생각보다 좋지 못하다면 해당 명령어를통해 토픽의 리더 파티션 쏠림 현상을 확인하는 것
    - 상세 보기
    - `bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --describe --topic hello.kafka.2`
- 설정변경

```
 we  ~/study/kafka_2.12-2.5.0  bin/kafka-configs.sh --bootstrap-server my-kafka:9092 \
--entity-type topics \
--entity-name hello.kafka \
--alter --add-config retention.ms=86400000
Completed updating config for topic hello.kafka.
 we  ~/study/kafka_2.12-2.5.0  bin/kafka-configs.sh --bootstrap-server my-kafka:9092 \
--entity-name hello.kafka \
--entity-type topics \
--describe
Dynamic configs for topic hello.kafka are:
  retention.ms=86400000 sensitive=false synonyms={DYNAMIC_TOPIC_CONFIG:retention.ms=86400000}
```

## 카프카 프로듀서 
- 메시지 키와 값을 함께 전송한 레코드는 토픽의 파티션에 저장된다.
- 키가 null인 경우 레도크 배치 단위로 라운드로빈으로 전송
- 메시지 키가 동일한 경우 동일한 파티션으로 전송 된다.
- 파티션 개수가 늘어나면 새로 프로듀싱 되는 레코드들은?
    - 메시지 키를 가진 레코드의 경우
        - 메시지 키의 일관성이 보장되지 않는다.
        - 이전 메시지 키가 0 파티션이었다면 파티션을 늘린 뒤에는 보장이 안된다. => 커스텀 파티셔너를 만들면 가능
```
 we  ~/study/kafka_2.12-2.5.0  bin/kafka-console-producer.sh --bootstrap-server my-kafka:9092 --topic hello.kafka

>hello
>kafka
>0
>1
>2
>3
>4
>^C%
 we  ~/study/kafka_2.12-2.5.0  bin/kafka-console-producer.sh --bootstrap-server my-kafka:9092 --topic hello.kafka \
> --property "parse.key=true" \
> --property "key.separator=:"
>key1:no1
>key2:no2
>key3:no3
```

## 카프카 컨슈머
- 컨슈머 그룹은 1개 이상의 컨슈머로 이루어짐 컨슈머 그룹을 통해 가져간 토픽의 메시지는 가져간 메시지에 대해 커밋한다
    - 커밋이란? 컨슈머가 특정 레코드끼리 처리를 완료했다고 레코드의 오프센 번호를 카프카 브로커에 저장하는 것
    - 커밋정보는 _consumer_offsets 이름의 내부 토픽에 저장된다.
```
 we  ~/study/kafka_2.12-2.5.0  bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 --topic hello.kaf
ka --from-beginning
no2
hello
0
1
2
3
no3
kafka
4
no1

 we  ~/study/kafka_2.12-2.5.0  bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 --topic hello.kafka \
> --property print.key=true \
> --property key.separator="-" \
> --group hello-group \
> --from-beginning
key2-no2
null-hello
null-0
null-1
null-2
null-3
key3-no3
null-kafka
null-4
key1-no1
```
- 전송했던 데이터의 순서가 보장되지 않음
    - 파티션 개념때문에 생기는 현상 => 토픽의 데이터를 가져가게 되면 토픽의 모든 파티션으로부터 동일한 중요도로 데이터를 가져간다.
    - 한 개의 파티션에는 데이터의 순서를 보장한다.


## 카프카 컨슈머 그룹
- 컨슈머 그룹의 상세 정보를 확인하는 것은 컨슈머를 개발/운영할 때 중요하게 활용된다. 그룹이 중복되지 않는지 확인하거나 운영하고 있는 컨슈머가 랙이 얼마인지 확인하여 컨슈머 상태를 최적화하는대 사용된다.
- 랙이 증가하고 있다는 의미는 프로듀서가 데이터를 토픽으로 전달하는 속도에 비해 컨슈머의 처리량이 느리다는 것이다. 카프카에 연결된 컨슈머의 호스트명 또는 IP를 알아내서 처리할 수도 있다.
```
 we  ~/study/kafka_2.12-2.5.0  bin/kafka-consumer-groups.sh --bootstrap-server my-kafka:9092 --group hello-group --describe

Consumer group 'hello-group' has no active members.

GROUP           TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID     HOST            CLIENT-ID
```
- GROUP: 조회한 컨슈머 그룹이 마지막으로 커밋한 토픽과 파티션을 나타낸다. 가장 첫번째 줄은 hello-group 이름의 컨슈머그룹이 hello.kafka 토픽의 3번 파티션의 레코드가 마지막으로 커밋되었다.
    - GROUP           TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID     HOST            CLIENT-ID
    - hello-group     hello.kafka     3          1               1               0               -               -               -
- CURRENT-OFFSET:  컨슈머 그룹이 가져간 토픽의 파티션에 가장 최근 오프셋이 몇번인지 알려준다. 
    - 오프셋이란? 파티션의 각 레코드에 할당된 번호이다.
    - 이 번호는 데이터가 파티션에 들어올 때마다 1씩 증가한다. hello.kafka 토픽의 3번 파티션에 가장 최근 오프셋은 1이다.
- LOG-END-OFFSET: 해당 컨슈머 그룹의 컨슈머가 어느 오프셋까지 커밋했는지 알 수 있다. CURRENT-OFFSET은 LOG-END-OFFSET보다 같거나 작은 값일 수 있다.
- LAG: 컨슈머 그릅이 토픽의 파티션에 있는 데이터를 가져가는데에 얼마나 지연이 발생하는지 나타내는 지표
    - 랙은 컨슈머 그룹이 커밋한 오프셋과 해당 파티션의 가장 최신 오프셋 간의 차이이다. 
- CONSUMER-ID: 컨슈머의 토픽(파티션)할당을 카프카 내부적으로 구분하기 위해 사용되는 ID. 이 값은 client id에 uuid 값을 붙여 자동할당되어 유니크한 값으로 설정된다.
- HOST: 컨슈머가 동작하는 host 명을 출력. 이 값을 통해 카프카에 붙은 컨슈머의 호스트 명 또는 IP를 알 수 있다.

## kafka-verifiable-producer
- kafka-verifiable로 시작하는 2개의 스크립트를 사용하면 String 타입 메시지 값을 코드없이 주고받을 수 있다.
- 카프카 클러스터 설치가 완료 된 후 토픽에 데이터를 전송하여 간단한 네트워크 통신할 때 유용하다.

~~~
bin/kafka-verifiable-producer.sh --bootstrap-server 3.112.1.42:9092 \
--max-messages 10 \
--topic verify-test
{"timestamp":1673361546103,"name":"startup_complete"}
[2023-01-10 23:39:06,360] WARN [Producer clientId=producer-1] Error while fetching metadata with correlation id 1 : {verify-test=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
{"timestamp":1673361546817,"name":"producer_send_success","key":null,"value":"0","offset":0,"partition":0,"topic":"verify-test"}
{"timestamp":1673361546820,"name":"producer_send_success","key":null,"value":"1","offset":1,"partition":0,"topic":"verify-test"}
{"timestamp":1673361546820,"name":"producer_send_success","key":null,"value":"2","offset":2,"partition":0,"topic":"verify-test"}
{"timestamp":1673361546820,"name":"producer_send_success","key":null,"value":"3","offset":3,"partition":0,"topic":"verify-test"}
{"timestamp":1673361546820,"name":"producer_send_success","key":null,"value":"4","offset":4,"partition":0,"topic":"verify-test"}
{"timestamp":1673361546821,"name":"producer_send_success","key":null,"value":"5","offset":5,"partition":0,"topic":"verify-test"}
{"timestamp":1673361546821,"name":"producer_send_success","key":null,"value":"6","offset":6,"partition":0,"topic":"verify-test"}
{"timestamp":1673361546821,"name":"producer_send_success","key":null,"value":"7","offset":7,"partition":0,"topic":"verify-test"}
{"timestamp":1673361546821,"name":"producer_send_success","key":null,"value":"8","offset":8,"partition":0,"topic":"verify-test"}
{"timestamp":1673361546821,"name":"producer_send_success","key":null,"value":"9","offset":9,"partition":0,"topic":"verify-test"}
{"timestamp":1673361546826,"name":"shutdown_complete"}
{"timestamp":1673361546826,"name":"tool_data","sent":10,"acked":10,"target_throughput":-1,"avg_throughput":13.812154696132596}
~~~
- --max-message는 kafka-verifiable-producer로 보내는 데이터 개수를 지정한다. 만약 -1을 한다면 종료될 때까지 계속 데이터를 토픽으로 보낸다.
- 메시지 별로 보낸 시간 메시지키, 값, 저장된 파티션, 오프셋 번호가 출력된다.
- 10개의 데이터가 다 보내면 통계값이 출력된다.

