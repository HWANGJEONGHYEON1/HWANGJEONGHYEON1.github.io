---
layout: post
title:  "[study] kafka - 1"
date:   2022-09-07 16:20:21 +0900
categories: kafka
---

> 카프카 스터디 1

# 탄생
- 소스 어플리케이션과 타깃 어플리케이션의 개수가 점점 많아져 데이터 전송하는 로직이 복잡해지기 시작.
- 링크드인은 내부 데이터 흐름을 개선하기 위해서 카프카 개발
- 각각의 어플리케이션끼리 연결하여 데이터를 처리하는 것이 아니라 중앙 한곳에 모아 처리할 수 있도록 중앙집중화 

## 데이터 파이프라인 특징
- `높은 처리량`
    - 카프카는 프로듀서가 브로커로 데이터를 보낼 때와 컨슈머가 데이터를 받을 때, 모두 묶어서 전송
    - 많은 양의 데이터를 송 수신할 때 맺어지는 네트워크의 비용은 크다.
    - 동일한 양의 데이터를 보낼 때 네트워크 통신 회수를 최소한으로 줄인다면 동일 시간 내에 많은 데이터를 전송할 수 있다.
    - 파티션 단위를 통해 동일 목적의 데이터를 여러 파티션에 분배하고 데이터를 병렬 처리할 수 있다.
    - 파티션 개수만큼 컨슈머 개수를 늘려 동일 시간당 데이터 처리량을 늘린다.
- `확장성`
    - 데이터가 얼마나 들어올지의 관한 예측은 어렵다.
    - 카프카는 가변적인 환경에서 안정적으로 확장 가능하도록 설계되었다.
    - 데이터가 적을 때 카프카 클러스터의 브로커를 최소한으로 유지하다가 데이터가 많아지면 브로커 개수를 자연스럽게 늘릴 수 있다.
    - `무중단으로 가능`
- `영속성`
    - 프로그램이 종료되더라도 데이터는 사라지지 않는다.
    - 데이터를 메모리저장하지 않고 파일 시스템에 저장
    - 카프카는 파일시스템에 페이지 캐시영역을 메모리에 따로 생성한다.
- `고가용성`
    - 3개 이상의 서버들로부터 카프카 클러스터는 일부 서버에 장애가 발생하더라도 무중단으로 안전하고 지속적으로 데이터를 처리할 수 있다.
    - 클러스터로 이루어진 카프카는 데이터의 복제를 통해 고가용성의 특징을 가진다.
    - 프로듀서로 전송받은 데이터를 여러 브로커중 1대의 브로커에만 저장하는것이 아니라, 또 다른 브로커에 저장한다.


## 카프카 내부
- 데이터가 저장되는 파티션의 동작은 FIFO방식의 큐와 유사하다.
- 큐에 데이터를 보내는것이 `producer`, 데이터를 가져가는것이 `consumer`이다.


# 기본 개념

## 카프카 브로커와 클러스터
- 주키퍼
    - 카프카 클러스터를 운영하기위해 반드시 필요한 어플리케이션
- 브로커
    - 하나의 인스턴스에서 동작
    - 데이터를 분산 저장하여 장애가 발생하더라도 안전하게 사용될 수 있도록 도와주는 어플리케이션
    - 컨트롤러
        - 클러스터의 다수 브로커 중 한 대가 컨트롤러 역할,
            - 역할: 다른 브로커들의 상태를 체크하고 브로커가 클러스터에서 빠지는 경우 해당 브로커에 존재하는 리더 파티션을 재 분배
        - 지속적으로 데이터를 처리해야하므로 브로커의 상태가 비정상적이라면 빠르게 클러스터에서 빼내는 것이 중요하다.
        - 컨트롤러 역할을 하는 브로커에 장애가 생기면 다른 브로커가 컨트롤러 역할을한다.
    - 데이터 삭제
        - 카프카는 다른 메시징 플랫폼과 다르게 데이터를 컨슘하더라도 데이터가 삭제되지 않는다.
        - 컨슈머나 프로듀서가 삭제를 요청할 수 없다. => 오직 브로커만 삭제할 수 있다.
        - 데이터삭제는 파일 단위로 이루어지는대, 이 단위를 로그 세그먼트라 한다.
    - 컨슈머 오프셋 저장
        - 컨슈머 그룹은 토픽이 특정 파티션으로부터 데이터를 가져가서 처리하고 파티션의 어느 레코드까지 가져갔는지 확인하기 위해 오프셋을 커밋한다.
        - 커밋한 오프셋은 _consumer, _offset 토픽에 저장한다.
    - `데이터의 저장`
        - config/server.properties의 log.dir 옵션에 정의한 디렉토리에 데이터를 저장한다.
        - 토픽 이름과 파티션 번호의 조합으로 하위 디렉토리를 생성하여 데이터를 저장
    - 복제
        - 클러스터로 묶인 브로커 중 일부에 장애가 발생하더라도 데이터를 유실하지 않고 안전하게 사용하기 위함.
        - 카프카의 데이터 복제는 파티션 단위로 이루어진다.
        - replication factor 최소값은 1 최대값은 브로커의 개수 만큼 설정가능
        - 복제된 파티션은 리더와 팔로워로 구성
- 클러스터
    - 여러개의 브로커가 존재
    - 최소 3개로 운영되도록 함
    - 프로듀서가 보낸 데이터를 안전하게 분산 저장하고 복제하는 역할을 수행

## 세그먼트(파일)와 삭제주기
- retention.ms(minutes, hours) : 세그먼트를 보유할 최대기간, 기본 값은 7일
- retention.bytes : 파티션당 로그 적재 바이트 값. 기본 값은 -1(지정하지 않음)
- log.retention.check.interval.ms: 세그먼트가 삭제 영역에 들어왔는지 확인하는 간격, 기본 값은 5분 
- `파일단위로 삭제됨`
- compact
    - 중복된 키 벨류가 있으면 오래된 레코드가 삭제된다
- 테일/헤드 영역
    - 테일영역: 압축 정책에 의해 압축이 완료된 레코드들, 클린 로그 -> 중복된 레코드가 없음
    - 헤드영역: 압축 정책이 되기 전 레코드들, 더티로그 -> 중복된 레코드가 있음


## 토픽과 파티션
- 토픽: 한 개 이상의 파티션을 소유
    - 파티션이 5개인 토픽을 생성했을 경우 round-robin 방식으로 리더파티션들이 생성된다.

- 파티션 : 프로듀서가 보낸 데이터들이 저장되는데 이 데이터를 레코드라고한다.
    - 특정 브로커에 파티션이 몰리는 경우 kafka-reassign-partitions.sh
    - 파티션과 컨슈머의 개수 1:1
    - 파티션개수를 늘리는것은 가능하지만 줄이는 것은 불가능(신중해야한다.)

## 레코드
- 타음스탬프, 헤더, 메시지 키, 오프셋으로 구성
- 프로듀서 생성한 레코드가 브로커로 전송되면 타임스탬프가 지정되어 저장
- 브로커에 한번 적재된 레코드는 수정할 수 없다.
- 오프셋
    - 레코드의 오프셋은 프로듀서가 생성한 레코드에는 존재하지 않는다.
    - 프로듀서가 전송한 레코드가 브로커에 적재될 때 지정

## 토픽 이름 정하기
- 빈문자열은 지원 X
- 영어 대소문자, 숫자, 마침표, 언더바, 하이픈 조합으로 생성할 수 있다.
- 토픽이름을 변경할 수 없다. (삭제 후 다시 생성)
- prod.service-api.sms.json
- commerce.sms.prod.notification 등 좋은 방법

## reference
- https://www.inflearn.com/course/%EC%95%84%ED%8C%8C%EC%B9%98-%EC%B9%B4%ED%94%84%EC%B9%B4-%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D