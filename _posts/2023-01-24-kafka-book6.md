---
layout: post
title:  "아파치 카프카 스터디 - 6"
date:   2023-01-24 23:20:21 +0900
categories: kafka, spring
---

> 아프치 카프카 애플리케이션 프로그래밍 스터디 - 6


# 목표?
- 회사에서 대용량 데이터를 처리하는것에 있어, 카프카를 사용하고 있으므로, 제대로된 학습을 통해 원하는 처리를 할 수 있도록 한다.

# 상세개념

* > 토픽
    - 카프카를 사용하는 것은 토픽을 만들면서 시작한다.
    - 토픽을 삭제하면 데이터는 삭제되고 파이프라인은 중단된다.
    - 데이터의 생명주기에는 토픽이 있다.

* > 파티션
    - 파티션 개수는 성능과 연관이 있어 토픽을 운영에 있어서 적절한 파티션 개수를 설정하고 운영하는 것이 중요하다.
    - 토픽 최초 생성시에 파티션의 개수를 정하는데에 고려해야할 점 
        1. 데이터 처리량
        2. 메시지 키 사용여부
        3. 브로커, 컨슈머 영향도
    - `파티션`은 카프카의 병렬처리의 핵심이다.
        - 파티션의 개수가 늘어날 수록 1:1 매핑되는 컨슈머 개수가 늘어나기 때문이다.
    - 데이터 처리 속도를 올리는 방법
        1. 컨슈머의 처리량을 늘리는 것
        2. 컨슈머를 추가해서 병렬처리량을 늘리는 것
        3. 파티션 개수를 늘리고 파티션 개수만큼 컨슈머를 추가하는 방법은 데이터 처리량을 늘리는 가장 확실한 방법이다.
        4. <b><i>프로듀서가 보내는 데이터양과 컨슈머의 데이터처리량을 계산해서 파티션 개수를 정하면 된다.</i></b>
        - ex) 만약 프로듀서가 보내는 데이터가 초당 천 개의 레코드이고, 컨슈머가 처리할 수 있는 레코드가 1000개라면, 최소한으로 필요한 파티션 개수는 10개이다. => 프로듀서 전송 데이터량 < (컨슈머 데이터 처리량 * 파티션 개수)
        - 파티션 개수만큼 컨슈머 스레드를 운영한다면, 해당 토픽의 병렬처리를 극대화 할 수 있다. 만약 전체 컨슈머 데이터처리량이 프로듀서가 보내는 데이터보다 적다면 컨슈머 렉이 생기고, 데이터 처리 지연이 발생. 
        - 그렇기 때문에 컨슈머 전체 데이터처리량이 프로듀서 데이터 처리량 보다 많아야한다.
    - 컨슈머 데이터 처리량을 구하는 방법
        - 상용에서 운영 중인 카프카에서 더미 데이터로 테스트를 해보는 것.
        - 카프카 컨슈머를 개발할 때 내부 로직을 고민하여 시간 복잡도를 줄이기 위해 다양한 노력을 해보는것도 좋다.
        - 컨슈머 데이터 처리량을 구하고 난 뒤에는 프로듀서가 보내는 데이터 양을 하루, 시간, 분 단위로 쪼개 예측한다.
        - 파티션 개수를 무조건 늘려도 좋지않다. 파티션 개수를 늘리게 됨으로써 컨슈머 브로커의 부담이 된다.
    - 메시지 키 사용여부
        - 메시지 키를 사용함과 동시에 데이터 처리 순서를 지켜야하는 경우에 대해 고려해야한다.
        - 메시지 키의 사용여부는 처리 순서와 밀접한 관련이 있다. 
        - ex) 프로듀서가 기본 파티셔너를 사용하는 경우
            - 메시지 키를 사용하면 프로듀서가 토픽으로 데이터를 보낼 때 메시지 키를 해시 변환하여 메시지 키를 파티션에 매칭시킨다.
            - 만약 파티션 개수가 달라지면 이미 매칭된 파티션과 메시지 키의 매칭이 깨지게 전혀 다른 파티션에 데이터가 할당된다.
            - 파티션 개수가 달라지는 순간에는 메시지 키를 사용하는 컨슈머는 메시지 키의 순서를 더는 보장받지 못한다. 파티션을 변환하기 이전과 이후의 메시지 키의 파티션 위치가 계속 달라지기 때문이다.
            - 처리 순서가 보장이 되어야한다면 파티션 개수가 달라지지 않게 운영해야한다.
                - 이런 경우에는 커스텀 파티셔너를 개발하여 적용해야하는데 어렵다.
                - 프로듀서가 전소앟는 데이터양보다 넉넉하게 잡고 생성하는 것이 좋다.
    - 브로커와 컨슈머의 영향도
        - 파티션이 늘어나는 만큼 파일개수가 많아진다.
        - 운영체제에서는 프로세서당 열 수 있는 파일 최대 개수를 제한하고 있다.

* > 토픽 정리 정책
    - 토픽의 데이터는 시간 또는 용량에 따라 삭제 규칙을 적용할 수 있다.
    - 데이터는 시간이 지남에 따라 유지, 삭제 할 수 있다.
        - 데이터를 더는 삭제하지 않을 경우에는 cleanup.policy 옵션을 사용하여 데이터를 삭제할 수 있는대, 옵션은 2가지를 제공한다.
            1. delete로 데이터의 완전삭제.
            2. compact로 동일 메시지키의 가장 오래된 데이터를 삭제하느 ㄴ것이다.
    - `delete 정책`        
        - 토픽을 운영하면 일반적으로 대부분의 토픽의 정책(cleanup.policy)을 delete로 설정한다.
        - 데이터를 삭제할 때는 세그먼트의 단위로 삭제를 진행.
            - 세그먼트: 파티션마다 별개로 생성되며 세그먼트의 파일 이름은 오프셋 중 가장 작은 값이 된다.
            - 세그먼트는 여러 조각으로 나뉜다. segment.bytes 크기보다 커질 경우에는 기존에 적재하던 세그먼트파일을 닫고 새로운 세그먼트를 열어 데이터를 저장한다.
            - segment.bytes 크기보다 커질경우에는 기존에 적재하던 세그먼트 파일을 닫고 새로운 세그먼트를 열어서 데이터를 저장한다. 데이터를 저장하기 위해 사용중이던 세그먼트를 액티브 세그먼트라고한다.
        - 삭제 정책이 실행되는 시점은 <b>시간 또는 용량 기준이 된다.</b>
            - retention.ms는 토픽의 데이터를 유지하는 기간을 밀리초로 설정할 수 있다.
            - 카프카는 일정 주기마다 세그먼트 파일의 마지막 수정 시간과 retention.ms를 비교하는데, 세그먼트 파일의 마지막 수정시간이 retention.ms를 넘어가면 세그먼트트 삭제된다.
            - retention.bytes는 토픽의 최대 데이터 크기를 제어한다. retention.bytes를 넘어간 세그먼트 파일들을 삭제된다. 삭제된 데이터트 복구할 수 없다.
    - `compact 정책`
        - zip의 압축과는 다른개념이다.
        - 여기서 `압축이란 메시지 키별로 해당하는 메시지키의 레코드 중 오래된 데이터를 삭제하는 정책`
        - 메시지 키를 기준으로 오래된 데이터를 삭제하기 때문에 삭제 정책과는 다르게 1개 파티션에서 오프셋의 증가가 일정하지 않을 수 있다. 
        - ex) 1~10까지 오르는 오프셋이 있고, 4,5,6이 동일한 메시지 키를 가질경우, 6에 비해 4번,5번 레코드는 오래된데이터이기 때문이다.
        - 이 정책은 스트림즈의 KTable과 같이 메시지 키를 기반으로 데이터를 처리할 경우 유용하다.
            - 데이터의 흐름이 아닌 가장 마지막 데이터가 중요할 경우 나머지 데이터는 삭제할 수 있기 때문이다.
        - 압축 정책은 엑티브 세그먼트를 제외한 나머지 세그먼트들에 한해 처리가 된다.
        - 데이터의 압축 시점은 min.cleanable.dirty.ratio 옵션 값에 따른다.
            - 세그먼트에 남아있는 데이터의 tail 영역의 레코드 개수와 헤드 영역의 레코드 개수의 비율을 뜻한다.
            - 테일 영역의 레코드들은 `클린 로그`라고 부르고 압축이 완료되었기 때문에 테일영역에는 중복된 키가 없다.
            - 헤드영역의 레코드들은 `더티 로그`라고 부르고 압축이 되기 전 레코드들이 있어 중복된 키가 있다.
        - 더티비율
            - 더티 영역의 메시지 개수를 압축 대상 세그먼ㅇ트에 남아있는 데이터의 총 레코드수로 나눈 비열
                - 만약 클린 영역에 3개의 레코드가 있고, 더티 영역에 3개가 있다면 0.5이다.(더티레코드개수 / (더티 + 클린 레코드 개수))
            - min.cleanable.dirty.ratio를 0.5로 설정할 경우 더티 비율이 0.5가 넘어가면 압축이 수행
            - 적절한 더티비율을 찾아 설정하는것이 중요

* > ISR (In-Sync-Replicas)
    - 리더 파티션과 팔로워 파티션이 모두 싱크가 된 상태
    - ex) 복제 개수가 2인 토픽 가정
        - 리터 파티션 1개와 팔로워 파티션이 1개 존재
        - 리더 파티션에 0~3까지 오프셋이 존재, 팔로워 파티션에 동기화가 완료되려면 0~3까지 오프셋이 존재해야 된다.
        - 리더 파티션과 팔로우 파티션이 동기화가된 상태에서는 리더 또는 팔로워 파티션이 위치하는 브로커에 장애가 발생하더라도 데이터를 안전하게 사용할 수 있다.
    - ISR 용어가 탄생하게 된 것은 팔로워 파티션이 리더 파티션으로부터 데이터를 복제하는 데에 시간이 걸리기 때문이다.
    - 프로듀서가 특정 파티션에 데이터를 저장하는 작업은 리더 파티션을 통해 처리된다. 이 때 리더 파티션에 새로운 레코드가 추가되어 오프셋이 증가하면 팔로워 파티션이 위치한 브로커는 리더 파티션의 데이터를 `복제`한다.
    - 리더 파티션에 데이터가 적재된 이후 팔로워 파티션이 복제하는 시간차 때문에 리더파티션과 팔로워 파티션 간에 오프셋 차이가 발생한다.
    - 이런 차이를 모니터링 하기 위해 리더파티션은 `replica.lag.time.max.ms` 값만큼의 주기를 가지고 팔로워 파티션이 데이터를 복제하는지 확인한다. replica.lag.time.max.ms보다 더 긴 시간동안 데이터를 가져가지 않는다면 해당 팔로워 파티션에 문제가 생긴것으로 판단하고 ISR 그룹에서 제외한다.
    - ISR로 묶이 리더와 팔로우는 파티션에 존재하는 데이터가 모두 동일하기 때문에 팔로우는 리더가 될 자격을 가진다. 반면, ISR로 묶이지 못한 팔로워들은 자격이 없다.
    - 일부 데이터 유실이 발생하더라도 서비스를 중단하지 않고, 지속적으로 토픽을 사용하고 싶다면 ISR이 아닌 팔로워 파티션을 리더로 선출하도록 설정할 수 있다. `unclean.leader.election.enable = true`
    - false일 경우 ISR이 아닌 팔로워 파티션을 리더 파티션으로 선출하지 않는다. 리더 파티션이 존재하는 브로커가 다시시작되기까지 기다린다. => <b>서비스 중단</b>
        - 대신 데이터 유실은 발생하지 않는다.
    - true인가 false인가?
        - 일부 데이터가 유실되더라도 토픽과 연동중인 서비스의 무중단 운영이 더 중요하다면 true
        - 데이터 유실이 안되는 경우에는 false
            - 이슈가 발생한 브로커가 다시 실행될때까지 기다려야하므로 서비스가 몇분에서 몇시간 중단될 수 있다.
    

* > 카프카 프로듀서
    - 카프카에 데이터를 저장하는 첫 단계이다.
    - 카프카 클러스터는 3대 이상의 브로커로 이루어져 있어야 일부 브로커에 이슈가 생기더라도 데이터의 유실을 막을 수 있다.
    - acks 옵션
        - 0, 1, -1 옵션에 따라 카프카 성능이 달라진다.
        - 복제개수가 1인 경우 성능변화는 크지 않다. 그러나 안정적으로 데이터를 운영하기 위해서는 복제개수가 2 이상으로 운영하는 경우가 대 부분이따.
        - acks = 0
            - 프로듀서가 리더 파티션으로 데이터를 전송했을 때, 리더 파티션으로 데이터가 저장되었는지 확인하지 않는다.
            - 리더 파티션은 데이터가 저장된 이후에 데이터가 몇 번째 오프셋에 저장되었는지 리턴하는데, 0으로 설정되 어있다면 프로듀서는 리더 파티션에 데이터가 저장되었는지 응답을 받지 않는다. 
            - 프로듀서가 데이터의 전송이 실패했을 때, retries 옵션을 설정할 수 있는대, 이 경우 무의미하다.
            - 데이터가 유실이 되어도 괜찮다면 0으로 설정하면 된다. 전송속도는 우수하다.
        - akcs = 1
            - 프로듀서는 리더 파티션에만 정상적으로 적재되었는지 확인한다.
            - 정상적으로 적재가 되어있지 않다면 적재될 때까지 재시도를 할 수 있다.
            - 그러나 리더파티션에 적재되었음을 보장하더라도 데이터는 유실될 수 있다.
                - 이유? 복제 개수를 2 이상으로 운영할 경우 리더파티션에 적재가 완료되었어도 팔로워 파티션에는 아직 동기화가 안되어있을 수도 있다. 팔로워 파티션이 데이터를 복제하기 직전에 리더 파티션에 장애가 발생한다면 데이터 유실이 된다.
            - 전송속도는 0보다는 느리다.
        - akcs = -1 or all
            - 리더 파티션과 팔로워 파티션에 모두 정상적으로 적재되었는지 확인한다.
            - 일부 브로커에 장애가 발생하더라도 프로듀서는 안전하게 데이터를 보낼 수 있음을 보장한다.
            - min.insync.replicas 옵션값에 따라 데이터의 안정성이 달라진다.
                - 값이 1이라면 ISR 중 최소 1개 이상의 파티션에 데이터가 적재되었음을 확인했다는것이다.
        - 상용에서는 일반적으로 브로커를 3대 이상으로 묶어 클러스터를 운영하는데, 이 점을 고려하여 프로듀서가 데이터를 가장 안정적으로 보내려면 토픽의 복제 개수는 3, min.insync.replicas를 2로 설정하고 acks를 all로 설정하는것을 추천한다.
    - `멱등성 프로듀서`
        - 멱등성이란? 여러 번 연산을 수행하더라도 동일한 결과를 나타내는 것, 동일한 데이터를 여러 번 전송하더라도 카프카 클러스터에 단 한번만 저장되는 것 
        - 기본 프로듀서의 동작 방식은 `적어도 한번 전달`을 지원한다.
            - 프로듀서가 클러스터에 데이터를 전송하여 저장할 때 적어도 한번 이상의 데이터를 적재할 수 있고 데이터가 유실되지 않음을 뜻한다. => 중복 가능성
        - 중뽁 적재를 막기 위해 `정확히 한번 전달`을 지원한다 => enable.idempotence 옵션 사용
            - 기본 값은 false
            - 데이터를 브로커에 전달할 때 프로듀서 PID와 시퀀스 넘버를 함께 전달한다. 그러면 브로커는 프로듀서가 PID와 시퀀스넘버를 확인하여 동일한 메시지가 오더라도 단 한번만 적재한다.
        - 재전송 횟수를 정하는 retrie 기본 값은 Integer.MAX_VALUE로 설정되고 acks 옵션은 all로 설정된다. 
            - 적어도 한번 이상 브로커에 데이터를 보냄으로써 브로커에 단 한번만 데이터가 적재되는 것을 보장하기 때문이다.
            - 상황에 따라 프로듀서가 여러 번 데이터를 확인하고 중복된 데이터는 적재하지 않는다.
        - 멱등성 프로듀서의 시퀀스 넘버는 0부터 시작하여 순차적으로(1,2,3.. ) 값이 전달되는대, 값이 1 다음 3이 온다면 OutOfOrderSequenceException이 발생할 수 있다.
    - `트랜잭션 프로듀서`
        - 다수의 파티션에 데이터를 적재할 경우 모든 데이터에 대해 동일한 원자성(atomic)을 만족하기 위해 사용된다.
        - 원자성을 만족시키는 의미는 다수의 데이터를 동일 트랜잭션으로 묶음으로서 전체 데이터를 처리하거나 전체 데이터를 처리하지 않도록 하는 것을 의미한다.
        - 컨슈머는 기본적으로 프로듀서가 보내는 데이터가 파티션에 쌓이는 대로 모두 가져가서 처리한다. 그러나 트랜잭션으로 묶인 데이터를 브로커에서 가져갈 때는 다르게 동작하도록 설정할 수 있다.
        - 트랜잭션 프로듀서를 사용하려면 enable.idempotence = true 설정, transaction.id를 임의의 String 값으로 정의한다.
        - 컨슈머의 isolation.level을 read_committed로 설정하면 프로듀서와 컨슈머는 트랜잭션으로 처리 완료된 데이터만 쓰고 읽게 된다.
        - 트랜잭션은 파티션의 레코드로 구분한다.
            - 트랜잭션 프로듀서는 사용자가 보낸 데이터를 레코드로 저장할 뿐만 아니라 트랜잭션의 시작과 끝을 표현하기 위해 트랜잭션 레코드를 한 개 더 보낸다.
            - 트랜잭션 컨슈머는 파티션에 저장된 트랜잭션 레코드를 보고 트랜잭션이 완료(commit)되었음을 확인하고 데이터를 가져간다.
            - 실질적인 데이터는 가지고 있지 않으며, 트랜잭션이 끝난 상태를 표시하는 정보만 가지고 있다. => 레코드의 특성은 가지고 있기 때문에 파티션에 저장되어 오프셋을 한 개 차지한다.
            - 커밋이 완료된 데이터가 있을 경우에만 데이터를 가져가고, 그렇지 않으면 처리하지 않는다.