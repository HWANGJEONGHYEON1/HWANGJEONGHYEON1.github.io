---
layout: post
title:  "[study] kafka - 3"
date:   2022-10-05 16:20:21 +0900
categories: kafka
---

> 카프카 스터디 3

## 프로듀서
- 카프카에서 데이터의 시작점
- 카프카에 필요한 데이터를 선언하고 브러코의 특정 토픽의 파티션에 전송
- 프로듀서는 데이터를 전송할 때 리더 파티션을 가직고 있는 카프카 브로커와 직접 통신
- 리더가 아닌 파티션은 리더파티션을 복제하는 역할
- 카프카 브로커로 데이터를 전송할 때 내부적으로 파티셔너, 배치 생성 단계를 거친다.

### 내부구조
- ProducerRecord: 프로듀서에서 생성하는 레코드, 오프셋은 미포함
	- 오프셋은 카프카 클러스터로 전송된 후 생성된다.
- send() 레코드를 전송하는 요청 메서드
- Partioner: 어느 파티션으로 전송할지 지정하는 파티셔너, 기본값으로 DefaultPationer로 설정
- Accumulator: 배치로 묶어 전송할 데이터를 모으는 버퍼
- 레코드를 선언하고 send()를 호출하여 파티셔너,acuumalator를 거쳐 데이터를 보낸다.

### 파티셔너
- 프로듀서 API를 활용하면, UniformStickyPartioner, RoundRobinPartioner 2개 파티셔너를 제공한다.
- 메시지키가 있을경우 동작
	- UniformStickyPartioner와 RoundRobinPartioner 둘다 메시지 키가 있을때는 메시지 키의 해시값과 파티션을 매칭하여 레코드를 전송
	- 동일한 메시지 키가 존재하는 레코드는 동일한 파티션 번호를 전달됨
	- 만약 파티션 개수가 변경될 경우 메시지 키와 파티션 `번호 매칭은 깨지게 됨`
		- => 파티션 개수를 충분히 늘리자.
- 메시지가 없을 때
	- 파티션에 최대한 동일하게 분배하는 로직이 있는대 UniformStickyPartioner는 RoundRobinPartioner를 단점을 개선
- RoundRobinPartioner
	- 들어오는대로 파티션을 순회
	- 어큐뮤레이터에서 묶인느 정도가 적기 때문에 전송 성능이 낮음
- UniformStickyPartioner
	- 배치로 묶일뿐 결국 파티션 순회하면서 보내기 때문에 모든 파티션에 분배되어 전송됨

#### 프로듀서의 커스넘 파티셔너
	- 자바에서는 파티셔너 인터페이스를 제공
	- 메시지키 또는 메시지 값에 따라 파티션 지정 로직을 적용할 수 있다.
	- 메시지 키, 값에 따른 파티션 지정로직을 적용 가능
	- 파티셔너를 통해 파티션이 지정된 데이터는 어큐뮬레이터에 버퍼로 쌓인다.
	- 센더 스레드는 어뮤큘레이터에 쌓인 배치 데이터를 가져가 카프카 브로커로 전송

### 프로듀서 주요옵션 
- bootstrap.servers: 프로듀서가 데이터를 전송할 대상 카프카 클러스터에 속한 브로커의 호스트이름:포트를 1개 이상 작성한다. 두 개 이상 브로커정보를 입력하여 일부 브로커에 이슈가 발생하더라도 접속하는 데에 이슈가 없도록 설정가능하다.
- key.serializer: 레코드의 메시지 키를 직렬화하는 클래스를 지정한다.
- value.serializer: 레코드의 메시지 값을 직렬화하는 클래스를 지정한다.
	- string-serializer가 용이
- acks: 프로듀서가 전송한 데이터가 브로커들에게 정상적으로 저장되었는지 전송 성공 여부 확인하는데에 용이한 옵션. 0, 1, -1(all) 중 하나로 설정할 수 있다. 기본 값은 1
- linger.ms: 배치를 전송하기 전까지 기다리는 최소시간. 기본 값은 0
- retires: 브로커로부터 에러를 받고 재전송을 시도하는 횟수를 지정한다. 기본값은 2147... 이다.
- max.in.flight.request.per.connection: 한 번에 요청하는 최대 커넥션 개수. 설정된 값 만큼 동시에 전달요청을 수행. 기본 값은 5
- partioner.class: 레코드를 파티션에 전송할 때 적용하는 파티셔너 클래스를 지정한다. 기본값은 DefaultPartitioner.
- enable.idempotence: 멱등성 프로듀서로 동작할지 여부를 설정. 기본 값은 false
- transactional.id: 프로듀서가 레코드를 전송할 떄 레코드를 트랜잭션 단위로 묶을지 여부를 설정한다. 기본 값은 null

#### ISR(In-Sync-Recplicas)
> 리더 파티션과 팔로워 파티션이 모두 싱크가 된 상태. 

- acks (`프로듀서 옵션`)
	- 옵션을 통해 카프카 클러스터에 얼마나 신뢰성을 높게 저장할지 지정 할 수 있다.
	- acks 옵션에 따라 성능이 달라진다
		- 성능이 높아지면 신뢰도가 낮아진다.
		- 리더와 팔로워 파티션의 레코드 개수 동일햇을 때 신뢰도가 젤 높다.
- acks = 0
	- 프로듀서가 리더 파티션으로 데이터를 전송햇을 때 리더 파티션으로 데이터가 저장되었는지 확인하지 않는다는 뜻.
	- 속도가 가장 빠르지만, 신뢰도가 낮다.(데이터를 보냈지만, 네트워크 장애로 데이터를 못받을 수 있다.)
	- 즉, 응답 값을 받지 않는다.
	- 데이터가 일부 유실되더라도 전송 속도가 중요한 경우에는 옵션값을 사용하면 좋다.
	- GPS(네비게이션) 같은..
- acks = 1
	- 프로듀서는 보낸 데이터가 리더 파티션에 정상적으로 적재되었는지 확인
	- 리더 파티션에 정상적으로 적재되지 않는다면 리더 파티션에 적재될 때까지 재시도 할 수 있다. 그러나 리더 파티션에 적재되었음을 보장하더라도 데이터는 유실될 수 있다.
- akcs = -1
	- 프로듀서가 보낸 데이터를 리더 파티션과 팔로워 파티션에 정상적으로 적재되었는지 확인한다.
	- 속도가 느리다.
	- 데이터 처리량이 많다면 이 옵션으로 하면 느리다.


## 컨슈머
> 프로듀서가 전송한 데이터는 카프카 브로커에 적재된다. 컨슈머는 적재된 데이터를 사용하기위해 브로커로부터 데이터를 가져와서 처리한다. 예를들어, 마케팅 문자를 고객에게 보내는 기능이 있다면, 컨슈머는 토픽으로부터 고객 데이터를 가져와 문자 발송 처리를 하게 된다.

### 내부구조
- Fetcher: 리더 파티션으로부터 레코드들을 미리 가져와서 대기
- poll(): Fetcher에 있는 레코드들을 리턴하는 레코드 
- ConsumerRecords: 처리하고자 하는 레코드들의 모음. 오프셋이 포함되어 있다.

### 컨슈머 그룹
- 컨슈머를 각 컨슈머 그룹으로부터 격리된 환경에서 안전하게 운영할 수 있도록 도와주는 카프카의 독특한 방식
- 컨슈머 그룹으로부터 묶인 컨슈머들은 토픽의 1개 이상 파티션들에 할당되어 데이터를 가져갈 수 있다.
- 컨슈머 그룹으로 묶인 컨슈머가 토픽을 구독해서 데이터를 가져갈 수 있다.
- 컨슈머 그룹의 캐수는 가져가고자 하는 토픽의 파티션 개수보다 같거나 작어야한다. 
- 컨슈머 그룹의 컨슈머가 파티션 개수보다 많을 경우
	- `유휴 상태`
	- 애플리케이션 실행에 있어 불필요한 스레드가 생긴다
- 그룹을 활용하는 이유
	- 최종 적재되는 저장소의 장애에 유연하게 대응할 수 있도록 각기 다른 저장소에 저장하는 컨슈머를 다른 컨슈머 그룹으로 묶음으로써 각 저장소의 장애에 격리되어 운영할 수 있다.


## reference
- https://www.inflearn.com/course/%EC%95%84%ED%8C%8C%EC%B9%98-%EC%B9%B4%ED%94%84%EC%B9%B4-%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D