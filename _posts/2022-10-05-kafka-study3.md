---
layout: post
title:  "[study] kafka - 3"
date:   2022-10-05 16:20:21 +0900
categories: kafka
---

> 카프카 스터디 3

## 프로듀서
- 카프카에서 데이터의 시작점
- 카프카에 필요한 데이터를 선언하고 브로커의 특정 토픽의 파티션에 전송
- 프로듀서는 데이터를 전송할 때 리더 파티션을 가지고 있는 카프카 브로커와 직접 통신
- 리더가 아닌 파티션(팔로워파티션)은 리더파티션을 복제하는 역할
- 카프카 브로커로 데이터를 전송할 때 내부적으로 파티셔너, 배치 생성 단계를 거친다.

### 내부구조
- ProducerRecord: 프로듀서에서 생성하는 레코드, 오프셋은 미포함
	- 오프셋은 카프카 클러스터로 전송된 후 생성된다.
- send() 레코드를 전송하는 요청 메서드
- Partioner: 어느 파티션으로 전송할지 지정하는 파티셔너, 기본값으로 DefaultPationer로 설정
- Accumulator: 배치로 묶어 전송할 데이터를 모으는 버퍼
- 레코드를 선언하고 send()를 호출하여 파티셔너,acuumalator를 거쳐 데이터를 보낸다.

### 파티셔너
- 프로듀서 API를 활용하면, UniformStickyPartioner, RoundRobinPartioner 2개 파티셔너를 제공한다.
- 메시지키가 있을 경우 동작
	- UniformStickyPartioner와 RoundRobinPartioner 둘다 메시지 키가 있을때는 메시지 키의 해시값과 파티션을 매칭하여 레코드를 전송
	- 동일한 메시지 키가 존재하는 레코드는 동일한 파티션 번호를 전달됨
	- 만약 파티션 개수가 변경될 경우 메시지 키와 파티션 `번호 매칭은 깨지게 됨`
		- => 파티션 개수를 충분히 늘리자.
- 메시지가 없을 때
	- 파티션에 최대한 동일하게 분배하는 로직이 있는대 UniformStickyPartioner는 RoundRobinPartioner를 단점을 개선
- RoundRobinPartioner
	- 들어오는대로 파티션을 순회
	- 어큐뮤레이터에서 묶인느 정도가 적기 때문에 전송 성능이 낮음
- UniformStickyPartioner
	- 배치로 묶일뿐 결국 파티션 순회하면서 보내기 때문에 모든 파티션에 분배되어 전송됨

#### 프로듀서의 커스넘 파티셔너
	- 자바에서는 파티셔너 인터페이스를 제공
	- 메시지키 또는 메시지 값에 따라 파티션 지정 로직을 적용할 수 있다.
	- 메시지 키, 값에 따른 파티션 지정로직을 적용 가능
	- 파티셔너를 통해 파티션이 지정된 데이터는 어큐뮬레이터에 버퍼로 쌓인다.
	- 센더 스레드는 어뮤큘레이터에 쌓인 배치 데이터를 가져가 카프카 브로커로 전송

### 프로듀서 주요옵션 
- bootstrap.servers: 프로듀서가 데이터를 전송할 대상 카프카 클러스터에 속한 브로커의 호스트이름:포트를 1개 이상 작성한다. 두 개 이상 브로커정보를 입력하여 일부 브로커에 이슈가 발생하더라도 접속하는 데에 이슈가 없도록 설정가능하다.
- key.serializer: 레코드의 메시지 키를 직렬화하는 클래스를 지정한다.
- value.serializer: 레코드의 메시지 값을 직렬화하는 클래스를 지정한다.
	- string-serializer가 용이
- acks: 프로듀서가 전송한 데이터가 브로커들에게 정상적으로 저장되었는지 전송 성공 여부 확인하는데에 용이한 옵션. 0, 1, -1(all) 중 하나로 설정할 수 있다. 기본 값은 1
- linger.ms: 배치를 전송하기 전까지 기다리는 최소시간. 기본 값은 0
- retires: 브로커로부터 에러를 받고 재전송을 시도하는 횟수를 지정한다. 기본값은 2147... 이다.
- max.in.flight.request.per.connection: 한 번에 요청하는 최대 커넥션 개수. 설정된 값 만큼 동시에 전달요청을 수행. 기본 값은 5
- partioner.class: 레코드를 파티션에 전송할 때 적용하는 파티셔너 클래스를 지정한다. 기본값은 DefaultPartitioner.
- enable.idempotence: 멱등성 프로듀서로 동작할지 여부를 설정. 기본 값은 false
- transactional.id: 프로듀서가 레코드를 전송할 떄 레코드를 트랜잭션 단위로 묶을지 여부를 설정한다. 기본 값은 null

#### ISR(In-Sync-Recplicas)
> 리더 파티션과 팔로워 파티션이 모두 싱크가 된 상태. 

- acks (`프로듀서 옵션`)
	- 옵션을 통해 카프카 클러스터에 얼마나 신뢰성을 높게 저장할지 지정 할 수 있다.
	- acks 옵션에 따라 성능이 달라진다
		- 성능이 높아지면 신뢰도가 낮아진다.
		- 리더와 팔로워 파티션의 레코드 개수 동일햇을 때 신뢰도가 젤 높다.
- acks = 0
	- 프로듀서가 리더 파티션으로 데이터를 전송햇을 때 리더 파티션으로 데이터가 저장되었는지 확인하지 않는다는 뜻.
	- 속도가 가장 빠르지만, 신뢰도가 낮다.(데이터를 보냈지만, 네트워크 장애로 데이터를 못받을 수 있다.)
	- 즉, 응답 값을 받지 않는다.
	- 데이터가 일부 유실되더라도 전송 속도가 중요한 경우에는 옵션값을 사용하면 좋다.
	- GPS(네비게이션) 같은..
- acks = 1
	- 프로듀서는 보낸 데이터가 리더 파티션에 정상적으로 적재되었는지 확인
	- 리더 파티션에 정상적으로 적재되지 않는다면 리더 파티션에 적재될 때까지 재시도 할 수 있다. 그러나 리더 파티션에 적재되었음을 보장하더라도 데이터는 유실될 수 있다.
- akcs = -1
	- 프로듀서가 보낸 데이터를 리더 파티션과 팔로워 파티션에 정상적으로 적재되었는지 확인한다.
	- 속도가 느리다.
	- 데이터 처리량이 많다면 이 옵션으로 하면 느리다.


## 컨슈머
> 프로듀서가 전송한 데이터는 카프카 브로커에 적재된다. 컨슈머는 적재된 데이터를 사용하기위해 브로커로부터 데이터를 가져와서 처리한다. 예를들어, 마케팅 문자를 고객에게 보내는 기능이 있다면, 컨슈머는 토픽으로부터 고객 데이터를 가져와 문자 발송 처리를 하게 된다.

컨슈머 그룹과 컨슈머
모든 컨슈머들은 단 하나의 컨슈머 그룹에 소속되어야한다. 컨슈머 그룹은 1개 이상의 컨슈머를 가질 수 잇음. 파티션의 레코드들은 단 하나의 컨슈머에만 할당
보통 파티션의 개수만큼 컨슈머의 개수가 있는게 이상적이다.
(컨슈머가 하나면 파티션에 들어오는 개수만큼 처리를해야하는대 병목현상이 발생) 
모든 컨슈머들은 고유한 그룹 아이디를 가지는 컨슈머 그룹에 소속되어야함 컨슈머 그룹내에서 여러개의 컨슈머들은 토픽 파티션 별로 분배됨, 서로 다른 컨슈머 그룹의 컨슈머들은 분리되어 독립적으로 동작
컨슈머 그룹내에 consumer의 변화가 있을 시마다 파티션과 consumer 조합을 변경하는 rebalancing 발생

컨슈머 그룹
1. 가용성
    1. 서버 1대일 경우 작업중단
    2. 서버가 4대일 경우 1대가 장애가나도 나머지가 작업을 이어나감
2. 컨슈머 그룹을 구분하고 그룹들은 자신의 그룹에 대해 offset을 가지고 잇음
    1. 컨슈머 그룹을 사용하면 동일한 토픽을 여러 컨슈머그룹이 컨슘하더라도 각기 다른 offset을 가지고 있어 데이터의 손실 없이 가져갈 수 있음
3. 컨슈머그룹과 파티션 수의 관계
    1. 카프카에서는 하나의 파티션에 대해 컨슈머 그룹내 하나의 컨슈머 인스턴스만 접근할 수 있다. => 파티션에 대해 한명의 reader만 허용하여 데이터를 순서대로 읽어갈수 있게 하기 위함(ordering 보장) 파티션 수보다 컨슈머 그룹의 인스턴스 수가 많을 수 없다.
    2. 가장 이상적이 상태 토픽의 파티션 개수 = 컨슈머 그룹 인스턴스 (4개 파티션 = consumer-group-1 의 컨슈머 4개)

ACKS
- 프로듀서가 사용하는 acks 옵션은 프로듀서가 메시지를 보내고 그 메시지를 카프카가 잘 받았는지 확인을 할 것인지 안할것인지 결정하는 옵션
1. acks
    1. Acks = 0 : 프로듀서는 보내기만하고 확인하지않음
        1. IoT 센서, 네비게이션 등 계속 데이터를 송신하여 유실되어도 괜찮은 데이터
    2. Acks = 1 : 프로듀서는 자신이 보낸 메시지에 대해 카프카의 리더가 메시지를 받았는지 기다림, follower들은 확인하지 않음, leader가 확인 응답을 보내고 follower에게 복제가 되기전에 leader가 fali 되면 해당메시지는 손실 될 수 있음
    3. Acks = -1 : leader와 follower가 받았는지 기다림, 최소 하나의 복제본까지 처리된 것을 확인하므로 메시지가 손실될 확률은 거의없
        1. 프로듀서는 리더브로커가 메시지를 받은 후 min.insync.replicas 개수 만큼 replicator에 복제를 수행한ㄷ 뒤 ack 메시지를 받은 후 다음 메시지인 메시지 b를 전송, 오류 메시지를 브로커로부터 받으면 재전송
        2. 메시지 A가 들어왔을 때, replicator에 완벽하게 복사되었는지의 여부까지 확인 후 다음 메시지 전송
        3. 메시지 손실이 되지 않도록 모든 장애상황을 감안하여 전송하지만 ack을 전부 받아야하기 때문에 느리다.
2. Min.insync.replicas
    1. 프로듀서가 acks = all 로 설정하여 메시지를 보낼 때, wirte를 성공하기 위한 최소 복제본의 수
    2. 브로커의 옵션임, 프로듀서 옵션이 아님 (config/server.properties) 기본 값은 1
    3. Replication factor 수의 따라 프로듀서의 메시지가 성공 또는 실패가 결정됨
    4. min.insync.replicas = 2, replication factor 3 이 바람직하다.

ISR
- Replication group
- ISR 내의 모든 follower 들은 누구라도 leader가 될 수 있다.
    - 데이터 동기화가 잘 되어 있어야함
- 팔로워가 다운되는 경우
    - 리더가 계속 살아있기 때문에 정상적으로 수행
- 리더가 다운되는 경우
    - 리더는 팔로워중 일정기간 동안 뒤쳐지면 리더가 될 자격이 없다 생각하여 isr에서 제외시킴, 짧은주기로 서로 체크하면서 leader와 데이터 동기화하여 리더 승격
- ALL DOWN
    - 마지막까지 leader 였던 브로커가 up이되고 다시 leader가 될 때까지 기다린다.( 모든 데이터를 가지고 있을 가능성), ISR과 상관없이 up 되는 토픽이 리더가 된다.
    - 카프카에서는 2번째 방법이 default
        - 기존 리더파티션에 적재된 데이터 유실이 있음 
    - 카프카에서 정말 중요한 데이터는 kafka-mirror-maker를 이용하여 다른 kafka로 미러링한다.

리벨런싱 
컨슈머 그룹내에 컨슈머 변화가 있을때마다 파티션과 컨슈머의 조합을 변경하는 리밸런싱 발생

Kafka producer send
- 전송은 프로듀서 클라이언트의 별도 스레드가 전송을 담당한다는 점에서 스레드 간 async 전송
- Producer client의 main thread가 send() 메소드를 호출하여 메시지를 전송을 시작하지만 바로 전송되지 않고 버퍼에 메시지를 저장 후 별도의 스레드가 kafka 브로커에 실제 전송을 하는 방식
로직
1. 프로듀서 환경 설정
2. 1에서 설정한 환경 설정값을 반영하여 KafkaProducer 객체 생성
3. 토픽명과 메시지 값을 입력하여 보낼 메시지인 ProducerRecorder 객체 생성

### 내부구조
- Fetcher: 리더 파티션으로부터 레코드들을 미리 가져와서 대기
- poll(): Fetcher에 있는 레코드들을 리턴하는 레코드 
- ConsumerRecords: 처리하고자 하는 레코드들의 모음. 오프셋이 포함되어 있다.

### 컨슈머 그룹
- 컨슈머를 각 컨슈머 그룹으로부터 격리된 환경에서 안전하게 운영할 수 있도록 도와주는 카프카의 독특한 방식
- 컨슈머 그룹으로부터 묶인 컨슈머들은 토픽의 1개 이상 파티션들에 할당되어 데이터를 가져갈 수 있다.
- 컨슈머 그룹으로 묶인 컨슈머가 토픽을 구독해서 데이터를 가져갈 수 있다.
- 컨슈머 그룹의 캐수는 가져가고자 하는 토픽의 파티션 개수보다 같거나 작어야한다. 
- 컨슈머 그룹의 컨슈머가 파티션 개수보다 많을 경우
	- `유휴 상태`
	- 애플리케이션 실행에 있어 불필요한 스레드가 생긴다
- 그룹을 활용하는 이유
	- 최종 적재되는 저장소의 장애에 유연하게 대응할 수 있도록 각기 다른 저장소에 저장하는 컨슈머를 다른 컨슈머 그룹으로 묶음으로써 각 저장소의 장애에 격리되어 운영할 수 있다.


## reference
- https://www.inflearn.com/course/%EC%95%84%ED%8C%8C%EC%B9%98-%EC%B9%B4%ED%94%84%EC%B9%B4-%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D