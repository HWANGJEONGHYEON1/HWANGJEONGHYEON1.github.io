---
layout: post
title:  "아파치 카프카 스터디 - 7"
date:   2023-01-26 23:20:21 +0900
categories: kafka, spring
---

> 아프치 카프카 애플리케이션 프로그래밍 스터디 - 7


# 목표?
- 회사에서 대용량 데이터를 처리하는것에 있어, 카프카를 사용하고 있으므로, 제대로된 학습을 통해 원하는 처리를 할 수 있도록 한다.

# 상세개념

###  카프카 컨슈머

* > 멀티스레드 컨슈머
    - 카프카는 처리량을 늘리기 위해 파티션과 컨슈머 개수를 늘릴 수 있다.
    - 파티션을 여러개로 운영하는 경우 데이터를 병렬처리 하기 위해서 파티션 개수와 컨슈머 개수를 동일하게 하는것이 좋다.
    - 멀티스레드 컨슈머를 안전하게 운영하기 위해 고려사항
        - 하나의 프로세스 내부에 스레드가 여러 개 생성되어 실행되기 때문에 하나의 컨슈머 스레드에서 예외적 상황이 발생할 경우 프로세스 자체가 종료될 수 있고 다른 컨슈머 스레드에 영향을 미칠 수 있다.
        - 컨슈머 스레드들이 비정상적으로 종료될 경우 데이터 처리에서 중복 또는 유실이 발생할 수 있다.
        - 각 컨슈머 스레드들 간에 영향이 미치지 않도록 스레드 세이프 로직, 변수를 적용해야한다.
    - 컨슈머 스레드는 1개만 실행하고 데이터 처리를 담당하는 워커 스레드를 여러 개 실행하는 방법
    - 컨슈머 인스턴스에서 poll() 메서드를 호출하는 스레드를 여러 개 띄워서 사용하는 컨슈머 멀티 스레드 전략

* > 컨슈머 렉
    - 컨슈머 그룹과 토픽, 파티션 별로 생성된다. 1개의 토픽에 3개의 파티션이 있고 1개의 컨슈머 그룹이 토픽을 구독하여 데이터를 가져가면 커슈머 랙은 3개가된다.
    - 프로듀서가 보내는 데이터양이 컨슈머의 데이터 처리량보다 크다면 컨슈머 렉은 늘어난다.
    - 컨슈머 렉을 모니터링하는 것은 카프카를 통한 데이터 파이프라인을 운영하는 데에 핵심적인 역할을 한다.
        - 모니터링함으로써 컨슈머의 장애를 확인할 수 있고, 파티션 개수를 정하는 데에 참고할 수 있다.
        - ex) 2개의 파티션으로 구성된 2개의 컨슈머가 각각 할당되어 데이터를 처리한다고 가정해보자.
            - 프로듀서가 보내는 데이터량은 동일한대 파티션 1번의 컨슈머 랙이 늘어나는 상황이 발상한다면 1번 파티션에 할당된 컨슈머에 이슈가 발생했다고 유추할 수 있다.
    - 랙을 확인하는 방법   
        1. 카프카 명령어
            > bin/kafka-consumer-groups.sh --bootstrap-server my-kafka:9092 \ --group my-group --describe
        2. 컨슈머 어플리케이션의 metrics()
            ```java
            for (Map.Entry<MetricName, ? extends Metric> entry : kafkaConsumer.metrics().entrySet()) {
                if ("record-lag-max".equals(entry.getKey().name()) |
                "records-lag".equals(entry.getKey().name() |
                "records-lag-avg".equals(entry.getKey().name()))) {
                    Metric metric = entry.getValue();
                }
            } 
            ```
            - 컨슈머가 정상 동작할 경우만 확인
            - 모든 컨슈머 애플리케이션에 모니터링 코드를 중복해서 작성해야한다.
        3. 외부 모티러링 툴


### 실습 
- 요구사항
    1. 이름을 입력하고 자신이 좋아하는 색상을 고르는 버튼을 누르면 이벤트와 user-agent 정보를 카프카 토픽으로 전달
    2. 엘라스틱 서치에 적재
- 적재정책
    1. 일부 데이터가 유실되거나 중복 적재되어도 무관한 정책이라면 운영 난이도는 낮아진다.
    2. 정복없이 정확히 한번만 적재되는 정책이라면 운영난이도는 급 상승한다.
- 데이터 포맷
    1. VO
        - 객체를 선언하여 직렬화하여 전송하는 방법
        - 보편적이고 편리하지만 프로듀서와 컨슈머에서 동일한 버전의 객체를 선언해서 사용한다는 문제가 있다. -> VO가 변경될 경우 프로듀서 컨슈머 둘 다 소스코드 업데이트를 해야한다.
        - 직렬화된 객체는 kafka-console-consumer 명령어를 통해 출력할 경우 내부 데이터를 확인할 수 없다. 디버깅이 어려워 역질렬화 클래스가 필요하다.
    2. `JSON` 
        - 스키마의 변화의 유연성과 디버깅의 편리성을 고려
        - 키-값 구조를 가지고 있으므로 스키마의 변경에 유연하게 대처할 수 있다.
        - ES는 JSON 포맷 기반으로 파일을저장하기 때문에 별다른 포맷변경없이 데이터를 적재할 수 있는 장점이있다.
- `웹 페이지`
    - 사용자의 이벤트를 수집하는 웹 페이지는 html만 사용한다.
    - input 태그로 이름을 받는다.
    - button 태그를 생성하여 red, yellow, greeen, blue 생성
    - 버튼을 누르면 ajax를 사용하여 비동기 사용자 이벤트를 전송한다.
- 프로듀서
    - RestApi 클라이언트를 만들고 이벤트를 가공하여 토픽으로 전달하는 역할을 한다. 
    - RestController를 활용
    - 토픽을 전달할 때는 카프카 라이브러리를 사용
        - `KafkaTemplate` 프로듀서 구현
    - acks 고려
        - all로 설정하면 클러스터 또는 네트워크 장애가 발생할 경우 복구할 확률이 높지만 처리속도 좋지 않다.
        - 1, 0은 속도는 빠르지만 복구하지 못할 가능성이 있다.
        - `데이터 전송에 있어 일부 유실이나 중복이 발생하더라도 안정적이고 빠른 파이프라인인 1로 설정`한다. acks=1은  최소한 리더파티션에는 데이터가 적재되는것을 보장할 수 있다.
        - min.insync.replicas 설정은 akcs를 1로 설정한 경우 해당 설정을 무시하고 리더파티션에 계속 적재하므로 따로 설정할 필요가 없다. => acks=all 설정할 경우 토픽의 설정이 유효하다.
- 파티셔너
    - `기본 파티셔너인 UniformStickyPartitioner를 적용`
    - 재시도 설정은 네트워크 문제로 인하여 데이터가 정상적으로 전송되지 않았을 경우 재전송한다. 토픽으로 전송된 데이터의 중복이 발생할 수 있고, 전송 시점의 역전으로 인하여 적재된 데이터의 순서가 바뀔 수 있다. => 기본값사용
- 토픽
    1. 파티션 개수
        - 적재된 데이터에 이벤트 발생 시간이 있으므로, 해당 데이터 필드를 통해 이벤트 발생시간을 재조합 할 수 있다.
        - 데이터처리 순서를 지키지않아도 되므로 토픽의 파티션 개수는 2개 이상으로 설정한다.
    2. 메시지 키 사용여부
        - 메시지 키를 사용하고 커스텀 프로듀서 파티셔너를 사용하지 않을 경우 메시지 키의 해시값으로 파티션 분배가 되기 때문에 고민해야한다.
        - 추후 파티션이 증가하면 해시값 파티션의 매칭이 깨지기 때문에 메시지 키를 활용하고 특정 파티션에 할당되는 컨슈머를 운영할 경우 매우 복잡 곤란.
        - 프로젝트에서는 `데이터를 메시지 값에만 저장하고 키는 저장하지 않는다`
    3. 복제 개수
        - 복제 개수가 높을 수록 데이터의 복구확률이 높아진다.
        - 다만, 팔로워 파티션이 데이터를 복제하는데에 시간이 오래걸리고 용량도 그 만큼 늘어난다. 클러스터의 브로커 1대에 이슈가 발생했을 경우에도 안정적으로 데이터를 받기 위한 최소 설정을 2로 설정한다.
